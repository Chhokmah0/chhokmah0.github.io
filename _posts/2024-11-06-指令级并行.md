---
title: 高性能计算-第三章-指令级并行
date: 2024-12-01 22:31:00 +0800
categories: [笔记，高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
## 序 - 指令级并行

当一个程序员听到并行时，他们一般都会想到多核并行。不过本章主要关注点在于单核上的并行。

### 指令流水线

为了运行任何一条指令，处理器都需要做一系列流程，包含：

- 从内存中**取码**；
- 把取出的二进制码**解码**为多个指令；
- **执行**这些指令，其中包含一些可能的内存操作；
- 将结果**写回**寄存器。

整个流程很长，即使是简单地将两个寄存器中的值相加也需要 15-20 个 CPU 周期。为了隐藏这些延迟，现代 CPU 都采用流水线技术。

![流水线](/assets/Instruction_Level_Parallelism/pipeline.png)
_流水线技术_

流水线技术并没有减少实际的延迟。你仍需要支付 15 到 20 个周期来获得结果。但是对于一个长指令序列而言，其中的某一个指令看上去就只有取码的消耗。

基于这一点，硬件制造商更喜欢用 _每条指令的周期数（cycles per instruction, CPI）_ 作为 CPU 的主要性能指标。

对于一个完全流水线的 CPU，CPI 应该接近于 1。CPI 甚至可以低于 1！只要我们增加流水线的“宽度”，以便同时处理多条指令。由于缓存和大部分 ALU 是共享的，这种方法比新加一个核心更有效益。这种架构被称为 _超标量架构_，能在每个周期内执行多条指令，大部分现代 CPU 都属于这一类别。

只有指令流中的指令的操作逻辑完全独立时，才能有效使用超标量架构。然而，指令并不总是按照最理想的顺序到达，因此，现代 CPU 在可能的情况下会 _乱序执行_，以提高整体的利用率。

### 类比现实

想想我们的教育系统：

- 知识点是向着一群学生一起教授的；
- 一批新生会被分成不同的小组，由不同的老师带领，作业和课程材料在小组之间共享；
- 每年新生都会被教授相同的课程，以确保教师们始终教学。

类比成现代 CPU：

- CPU 使用 _SIMD（单指令多数据）_ 在不同的数据点（通常是 16、32、64 bytes）上执行相同的操作；
- 由多个执行单元，可以同时处理这些指令，并共享 CPU 的其它设施（通常是 2 到 4 个执行单元）；
- 指令以流水线的形式处理。

## 一 - 流水线冒险

流水线可以让你通过在单核上并行运行一些指令来隐藏指令延迟，但这也会带来一些潜在的问题，通常称为 _流水线冒险（pipeline hazards）_。即下一条指令无法在下一个时钟周期内执行。

1. **结构冒险**：发生在两条或多条指令需要 CPU 的同一部分；
2. **数据冒险**：发生在必须等待之前的某个指令计算出结果后才能够执行；
3. **控制冒险**：发生在 CPU 无法确定下一条指令时。

解决这些冒险的唯一方法是暂停流水线，直到拥堵消失。

![流水线暂停](/assets/Instruction_Level_Parallelism/bubble.png)
_流水线在执行阶段暂停_

- 在结构冒险中，必须等待执行单元准备好。这是性能的瓶颈，无法避免；
- 在数据冒险中，必须等待所需数据的计算。可以通过重组计算来缩短关键路径；
- 在控制冒险中，通常需要清空整个流水线并重新开始。这会浪费 15 到 20 个周期。可以通过完全消除分支，或者进行分支预测，从而使得 CPU 可以明确找到下一步需要执行的内容。
  
## 二 - 分支的损耗

当 CPU 进行条件跳转或者其它分支时，它不会在条件是否满足计算完之前无所事事，而是会立即开始推测性地执行看起来更有可能的分支。在执行过程中，CPU 会计算每条指令的分支被采取的次数，一段时间后， CPU 就会通过这些数据来预测分支。

### 一个实验

首先创建一个随机生成的数组：

```rust
const N: usize = 10000000;
let mut rng = rand::thread_rng();
let uniform = Uniform::new(0, 100);

let a: Vec<i32> = uniform.sample_iter(&mut rng).take(N).collect();
```

然后将所有小于 50 的数做一个求和：

```rust
let mut s = 0;
for &val in a.iter() {
    if val < 50 {
        unsafe {
            std::ptr::write_volatile(&mut s, s + val);
        }
    }
}
```

在这样的操作下，编译器给出的结果为：

```nasm
.LBB11_12:
        add rdx, 4
        cmp rdx, rax
        je .LBB11_13 ; 跳出循环部分
.LBB11_11:
        mov esi, dword ptr [rdx]
        cmp esi, 50
        jge .LBB11_12 ; 无法进行预测的部分
        add ecx, esi
        mov dword ptr [rsp + 64], ecx
        jmp .LBB11_12
.LBB11_13:
```

在上面的汇编代码中，可以注意到 jge 那一行就是无法进行预测的分支。
通过调整允许被累加的数的阈值，benchmark 如下：（我不会做指令周期的统计，所以这里是整个函数的运行时间）

| 阈值 | 时间 |
| ---- | ---- |
| <25  | 58ms |
| <50  | 74ms |
| <75  | 60ms |

![分支损失](/assets/Instruction_Level_Parallelism/probabilities.svg)
_（来自原文）重要部分的程序在不同阈值下的平均指令周期_

从上图中可以注意到一些信息：

- 这个图不是对称的，这是因为两个分支方向并不等价，当数大于阈值时，不需要执行加法操作；
- 在 80~90 处有一个局部极小的地方。在这里，需要做加法和不用做加法的分支的指令周期数不同，使得 P 从 100 减少时，整个的平均指令周期产生了下降。换句话说，85 以后分支预测不再占据性能预测的主要瓶颈；
- 值得注意的是，不经常发生的情况在分支预测上造成的并不多。这就是为什么程序员经常使用运行时判断检查边界情况：它并没有想象中的那么昂贵。

### 模式检测

在之前的例子中，似乎硬件是通过统计某个分支更经常向哪个方向进行跳转来进行预测，然而实际上，硬件可以识别到比“总是左”、“总是右”、“左右左右”更复杂的模式。

如果你在求和前对数组进行了排序，亦或者数组的大小只有 1000，这些都足以让 CPU 记住某些信息，从而加快之后的运行。

### 为编译器标记可能性

你可以提前为编译器标注哪个分支更有可能发生。在 rust 当中，可以做如下操作：

```rust
use likely_stable::likely;
let mut s = 0;
for &val in a.iter() {
    if likely(val < 50) {
        unsafe {
            std::ptr::write_volatile(&mut s, s + val);
        }
    }
}
```

## 三 - 无分支编程

### 谓词

我们可以使用三元运算符或者 bool 到 int 的转换逻辑来实现无分支的结构：

```rust
let mut s = 0;
for &val in a.iter() {
    unsafe {
        std::ptr::write_volatile(&mut s, s + val * (if val < 50 { 1 } else { 0 }));
        // or std::ptr::write_volatile(&mut s, s + val * (val < 50) as i32);
    }
}
```

在这样的代码下编译出来的结果为：

```nasm
.LBB15_3:
        mov r8d, dword ptr [rdi + rdx]
        ; start cmp
        cmp r8d, 50
        cmovge r8d, ecx
        add esi, r8d
        ; end add
        mov dword ptr [rsp + 20], esi
        add rdx, 4
        cmp rax, rdx
        jne .LBB15_3
```

（原文中表示直接按照源代码逻辑编译时，会产生乘法指令，所有才有后续优化。不过 cpp、rust 等编译器已经直接快进到了使用 cmovge 条件移动指令）

可以看到，编译出的指令码中并没有 jmp 指令，而是使用 mov 代替。

另一方面，我们也可以通过减法，这样就只需要通过 i32 的符号位来判断是否小于 50：

```rust
let mut s = 0;
for &val in a.iter() {
    unsafe {
        std::ptr::write_volatile(&mut s, s + val * (val - 50 < 0) as i32);
    }
}
```

这样编译出来的代码为：

```nasm
.LBB16_3:
        mov esi, dword ptr [rdi + rcx]
        ; start cmp
        lea r8d, [rsi - 50]
        sar r8d, 31
        and r8d, esi
        add edx, r8d
        ; end add
        mov dword ptr [rsp + 20], edx
        add rcx, 4
        cmp rax, rcx
        jne .LBB16_3
```

多了一行指令，所以平时的时候还是好好按逻辑写代码，有些优化就交给编译器就好。

这些技术统称为谓词，它实际上是个如下的数学公式：

$$
    x = c \cdot a + (1-c) \cdot b
$$

这种技术的好处是可以消除分支，而坏处是需要同时付出计算 a 和计算 b 的代价。在本例中计算 a 和 b 的代价都为 0，但在其它时候则不一定。

### 什么时候谓词会更有效

使用谓词消除了控制冒险，但是却引入了新的结构冒险，因为 add 指令必须等待 cmovge 执行完毕。
不过后者好解决的多，只要等待 cmov 执行完毕即可，而不用冲刷整个流水线。

不过在有些情况下还是保留原样会更有效：

![无分支](/assets/Instruction_Level_Parallelism/branchy-vs-branchless.svg)
_不同阈值下，分支代码和无分支代码的平均指令数_

从图中可以看到，当预测成功率在 75% 以上时（无论是哪一侧），分支代码运行的会比无分支代码要优秀。
事实上，编译器就会使用 75% 作为它会使用何种分支策略的阈值。很不幸，这种东西有时没法在编译期得知。

不过还是能解决的：

- 可以使用 PGO(profile-guided optimization) 来进行优化，统计每个分支的进入次数；
- 使用 likeliness 或编译器内置的函数来进行提示：GCC 中的 `__builtin_expect_with_probability`，clang 中的 `__builtin_unpredictable`，rust 中的 `core::intrinsics::select_unpredictable`；
- 可以用三元运算符或者数学计算来重构代码，这个基本是显式地告知编译器使用无分支代码。

（以下为原文）
“正确的方法”是使用分支提示，但不幸的是，编译器们缺乏对它们的支持。现在，当编译器后端正准备决定 cmov 是否更有用时，这些提示似乎已经丢失了。
在实现这一方面已经取得了一些进展，但目前还没有好的方法来强制编译器生成无分支的代码，所以有时最好的希望就是用汇编语言编写一小段代码。

### 更大的例子

**字符串**。你看，在大多数时候，字符串都是一个指向堆上的指针，这意味着你在使用它的时候不得不多次判断这个指针是否为空指针，这便是大量的跳转指令。

一种方法是将所有的空字符串的指针，都指向内存上的一个 `'\0'` 字符。这样子虽然每次使用空字符串时都需要读取内存，但是却免去了分支。

**二分搜索**。标准的二分搜索是可以使用无分支的方式实现的：

```cpp
int lower_bound(int x) {
    int *base = t, len = n;
    while (len > 1) {
        int half = len / 2;
        base += (base[half - 1] < x) * half; // will be replaced with a "cmov"
        len -= half;
    }
    return *base;
}
```

值得注意的是，rust 中的二分搜索函数已经是无分支版本：

```rust
while size > 1 {
    let half = size / 2;
    let mid = base + half;

    let cmp = f(unsafe { self.get_unchecked(mid) });
    base = select_unpredictable(cmp == Greater, base, mid);
    size -= half;
}
```

通常来讲，通过隐式或显式填充数据结构，使其操作迭代次数恒定，从而使数据结构无分支。有关更复杂的示例。

**数据并行编程**。无分支代码对于 SIMD 编程非常重要，因为 SIMD 本身就没有分支。就算 SIMD 需要运行不同的分支，也需要将两条分支的指令都输入到所有的处理器中。

在数组求和案例中，删去 volatile 方法，转而使用普通的：

```rust
let mut s = 0;
for &val in a.iter() {
    s += val * (val - 50 < 0) as i32;
}
black_box(s);
```

（rust 并没有进行 simd 优化，可能需要显式地写出，或者需要进行设置？）

编译器通常能够对没有分支或依赖关系的任何循环进行矢量化。另外一些特殊情况也可以矢量化，例如 reductions（函数式编程的术语）或者只包含一个 if-without-else 的简单循环。

## 四 - 指令表

交叉执行的不同阶段是数字电路中的一种普遍思想，它不仅适用于 CPU 主流水线，也适用于单独指令和存储器的层次。大多数执行单元都有自己的小流水线，可以在前一条指令之后的一两个周期内执行另一条指令。

在这种情况下，每条指令都应该考虑两种不同的损失：

- **延迟**：获取这条指令的结果需要多少周期；
- **吞吐量**：每个周期平均可以执行这条指令多少次。

一般来讲，你可以从一个叫做指令表的特殊文档来获取这些信息。

- 由于人们的思维习惯了成本“更多”表示“更差”的模型，所以人们大多使用吞吐量的倒数而不是吞吐量。
- 如果某个指令执行地特别频繁，则可以复制他的执行单元以增加其吞吐量——可以复制多个执行单元，但不能超过解码宽度，多的没有什么用处。
- 在这里，存在一些指令的延迟是 0，这意味着他们本身是调度指令，如 `jmp`、`mov r, r`（寄存器到寄存器的移动）。但它们仍然具有非零的倒数吞吐量，因为 CPU 的前端依然需要执行它们。
- 大多数指令都可以流水线化。如果一个指令有 $n$ 的倒数吞吐量，这通常意味着在 $n$ 的周期后可以执行下一条指令。（如果小于 1，以为着如果这里有多个可执行单元，每个执行单元都能在下一个周期内执行下一条指令）。一个值得注意的例外是整数除法，它的延迟和倒数吞吐量都很大，要么流水线得很差，要么完全无法流水线；
- 某些指令具有可变延迟，这不仅取决于操作数的大小，还取决于操作数的值。对于内存操作（包括像加法这样的融合操作），通常会将延迟定为最佳情况下的延迟（L1缓存命中）。

## 五 - 高吞吐量计算

优化延迟和优化吞吐量有很大的不同：

- 在优化数据结构查询、小型的一次性算法、分支算法时，往往需要查阅所有指令的延迟，构建指令的依赖图，然后尝试通过重新组织来缩短关键路径；
- 而在优化热点循环和处理大数据集的算法时，需要查阅指令的吞吐量，计算每次迭代中每条指令的使用次数来确定瓶颈的位置，并尝试重构循环，减少其使用频率。

上述建议仅适用于数据并行循环，即每次循环完全独立于前一次循环。如果相邻循环之间存在某种依赖关系，则可能会因数据冒险导致流水线停顿，下一次循环需要等待前一次完成。

### 示例

```rust
let mut s = 0;
for &val in a.iter() {
    s += val;
}
```

假设编译器没有矢量化这个循环。内存带宽足够大，访问内存不是问题。并且循环已经展开，因此不需要额外支付维护循环变量的开销。在这种情况下，计算过程变得非常简单：

```rust
let mut s = 0;
s += a[0];
s += a[1];
s += a[2];
s += a[3];
// ...
```

这样的计算速度能有多快？答案是每个元素 $a[i]$ 的累加恰好需要一个周期，因为每次迭代都需要一个周期将新的值累加到 $s$ 中。

但我们可以更快，在原文中，作者的机器上加法操作的吞吐量为 $2$，这意味着每个周期理论上可以执行两个加法操作。然而这在上面的代码里是不可能的，因为它有循环依赖，$s$ 累加后至少需要一个周期才能被用于下一个循环。

解决方案是使用两个累加器：

```rust
let mut s0 = 0;
let mut s1 = 0;
s0 += a[0];
s1 += a[1];
s0 += a[2];
s1 += a[3];
// ...
let s = s0 + s1;
```

现在，超标量 CPU 就可以同时执行这两条“线程”，整个计算不再受限于任何关键路径，从而将吞吐量提高了一倍。

### 一般情况

如果一条指令的延迟是 $x$，吞吐量为 $y$，那么你需要使用 $x \cdot y$ 个累加器才能充分利用其性能。这也意味着需要 $x \cdot y$ 个寄存器来保存这些累加器的值。这对 CPU 设计来说是个重要的考虑因素，因为寄存器的数量会影响高延迟指令的最大可以使用的执行单元数量。

这种技术主要用于 SIMD 指令，而不是标量代码。上面的代码可以进行泛化，从而比编译器更快地计算总和或进行其他归约操作。

总体来说，在优化循环时，我们通常只有一个或少数几个执行端口需要充分利用，并围绕它们设计其余的循环。由于不同指令可能使用不同的端口集，代码的瓶颈可能并不明显。在这种情况下，机器代码分析工具可以很好地定位小型汇编循环中的瓶颈。
