---
title: 高性能计算-第八章-外存
date: 2025-4-3 12:00:00 +0800
categories: [笔记, 高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
[原文](https://en.algorithmica.org/hpc/external-memory/)

## 序

对两个数求和需要花多长时间？作为最常使用的指令之一，只要数据已经被保存在寄存器里，那么 `add` 只需要一个周期。

但是在 `*c = *a + *b` 这种情况中，我们却需要先从内存中取出相应的操作数：

```nasm
mov eax, DWORD PTR [rsi]
add eax, DWORD PTR [rdi]
mov DWORD PTR [rdx], eax
```

从内存中获得任何数据时，总会产生数据传输的延迟。因此，内存请求并不会直接跑到它的目的地，而是先跑到一个复杂的地址转换和缓存层来减少延迟。

所以这个问题最准确的答案是：对两个数求和的时间取决于操作数的位置：

- 如果存储在 RAM 中，大约会需要 100ns，或者说用 200 个周期获取它，再用 200 个周期写回去。
- 如果操作数最近被访问过，那么它大概率已经被缓存并且很快就可以获取。不同的缓存层级（访问时间）具有不同的访问速度，最慢的可能要 ~50 个周期，最快的可能只有 4-5 个周期。
- 数据也可能存储在 _外存_ 上，此时可能需要花费 5ms，大约 $10^7$ 个时钟周期来访问它。

这样搞得性能差异主要是因为存储硬件和 CPU 芯片并不遵循相同的增长规律。就算五十年前他们的性能差不多，现在也已经差的很远了。

![内存和 CPU 硬件的增长](/assets/External_Memory/memory-vs-compute.png)

为了减少这一点，现代内存系统变得越来越层级化，高层级的缓存会以容量为代价换取更少的延迟。容量和延迟在不同的层级可能发生指数级的变化——尤其是外存——因此对于许多内存密集型的算法，优化它们的 IO 局部性变得尤为重要。

这促使我们构建一个新的数学模型，称为 _外存模型_。在这里，唯一的内存开销是块读取和块写入，对于涉及已经读取到有限的本地内存的数据，IO 都是零开销的。它催生了一个新的关于 _外存算法_ 的领域，也是我们之后要学习的东西。

## 一 - 内存层级

现代计算机内存系统是高度层级化的。较高的层会缓冲较低的层中被经常访问的数据以减少延迟，每层的性能和成本往往有着数量级的差异。

抽象化地说，不同的存储设备都可以被表述为一个存储容量 $W$ 和每次读写块数据的块大小 $B$。每种内存都有以下比较重要的特征：

- 总大小 $M$；
- 块大小 $B$；
- 延迟，也就是获得数据所花费的时间；
- 带宽，有些时候可能会高于块大小除以延迟，这意味着 I/O 操作可以并行执行；
- 成本，各种意义上的均摊成本，包含芯片价格、能源消耗、维护开销等。

这里有 2021 年的一些硬件信息：

| Type | $M$      | $B$ | Latency | Bandwidth | $/GB/mo |
| :--- | :------- | --- | ------- | --------- | :------ |
| L1   | 10K      | 64B | 2ns     | 80G/s     | -       |
| L2   | 100K     | 64B | 5ns     | 40G/s     | -       |
| L3   | 1M/core  | 64B | 20ns    | 20G/s     | -       |
| RAM  | GBs      | 64B | 100ns   | 10G/s     | 1.5     |
| SSD  | TBs      | 4K  | 0.1ms   | 5G/s      | 0.17    |
| HDD  | TBs      | -   | 10ms    | 1G/s      | 0.04    |
| S3   | $\infty$ | -   | 150ms   | $\infty$  | 0.02    |

### 易失性内存

RAM 以及更高层的内存被成为易失性内存，因为它们的数据会在断电时丢失。但是它足够快，这也就是为什么会被用于在计算机通电时保存数据。

从最快到最慢的易失性存储器有：

- CPU 寄存器：CPU 会使用寄存器来读取它的操作数和保存计算结果，可以说 CPU 主要就是和寄存器执行交互，访问它们是零延迟的。他们的数量十分有限（例如，只有 16 个通用的寄存器）。
- CPU 缓存：现代 CPU 往往会使用很多层缓存（L1、L2、L3，有时候甚至会到达 L4）。L1、L2 缓存往往是 CPU 核独享的，到了 L3 就变为不同核之间共享的。
- 随机访问存储器：这是第一种可扩展的存储器。如今你甚至可以在公有云上租到 TB 级别 RAM 的机器。

CPU 缓存系统中有个非常重要的概念是 _缓存行 (cache line)_，它是从 CPU 和 RAM 之间进行数据传输的基本数据单元。在大多数机器上，缓存行的大小都是 64 字节。也就是说内存被按照 64 字节大小分块，每次获取某一字节的数据时，机器都会把同一缓存行中的其它 63 字节的数据拿过来，而不管你要不要它们。

在 CPU 上的缓存行根据它的最近访问时间来确定自己的缓存等级。当被访问时会被放到最低的缓存层，随后随着时间流逝，如果没有被访问就会被驱逐到更高一层的缓存。程序员无法控制这个过程，但是了解这些工作的细节也是有益的。我们将在下一张讨论这些。

### 非易失性内存

CPU 缓存和 RAM 都只存储少量电子（这些电子在不通电时很容易泄露），而在非易失性存储器中，存储单元会保存几百个电子。这使得数据可以在不通电的情况下保存更长的时间，但代价则是性能和耐用性——几百个电子更容易和硅原子发生碰撞。

有很多方式可以持久地保存数据，但从程序员视角来看，主要有这些：

- SSD (Solid state drives, 固态硬盘)：SSD 一般有着较小的延迟 (0.1ms)，但是它们的成本也很高，因为它们的每个存储单元寿命有限，且只能写入有限的次数。不过 SSD 是固定的且没有活动部件，因此被经常使用于移动设备。
- HHD (Hard disk drives, 机械硬盘)：HHD 是一个带有读写头的物理上的旋转磁盘。为了读取一个数据，你需要等磁盘转动到指定位置，然后非常精确地将磁头指向目标位置。这导致了一个非常奇怪的延迟：随机读取一个字节可能和顺序读取 1MB 的数据花费相同的时间。由于硬盘是除了冷却系统外唯一运动的部分，HHD 经常会损坏（数据中心的 HHD 寿命大约是 3 年）。
- NAS (Network-attached storage, 网络附属存储)：NAS 使用网络设备来存储数据。现实中基本上有两种类型，第一种是 NFS (Network File System, 网络文件系统)，这是一种通过网络挂载另一台计算机的文件系统的协议。另外一种是基于 API 的分布式存储系统，最著名的是 Amazon S3，它由公有云的存储机器提供支持，内部经常会使用廉价的 HDD 或者什么奇特的存储设备。尽管 NFS 在同一个数据中心时有些时候会比 HDD 更快，但是公有云上的对象存储往往还是会有 50-100ms 的延迟。它们通常是高度分发和复制的，从而获得更好地可用性。

由于 SDD/HDD 显著的比 RAM 慢，因此这一层以及更低的层级都被称为 _外存_。

和 CPU 缓存不同，外存可以被显示控制，在有些时候非常有用。但是大多数情况下程序员只想将其抽象出来，并将其当作主存的扩展使用。在操作系统中会使用 _虚拟内存_ 实现这一点。

## 二 - 虚拟内存

早期的操作系统允许每个进程自由地读取和修改任何内存区域，包括那些分配给其他进程的内存区域。虽然这挺简约的，但是带来了很多问题：

- 如果一个进程是有 bug 或者有恶意的呢？我们如何放置进程修改其他进程的内存，同时又允许它们通过内存进行同步？
- 我们如何处理内存碎片？例如我们有 4MB 内存，进程 A 分配了 1MB，进程 B 分配了 2MB，随后进程 A 结束并释放了内存，此时进程 C 申请 2MB 的连续内存——这里就报错了因为我们只有两个分开的 1MB 内存。重启进程 B 或者停止它并把它所有的数据和指针挪动 1MB 也不是什么好方法。
- 我们如何访问非 RAM 的存储结构？我们怎么插入一个闪存然后从里面读取一个文件？

这些问题对于一些专门的计算系统不是那么重要（比方说 GPU，通常一次只有一个计算任务，拥有对计算的完整控制），但它们对于现代多任务操作系统来说是绝对必要的——操作系统使用一种叫做虚拟内存的技术解决了所有这些问题。

### 内存分页

虚拟内存给每个进程一个控制了连续空间存储的错觉，这些存储空间实际上会被映射到物理内存上很多更小的块——主存或者外存都可以。

![虚拟内存和物理内存的映射](/assets/External_Memory/virtual-memory.jpg)

为了实现这一点，内存物理空间被划分为 _页_（通常为 4KB 大小），也是程序可以通过操作系统申请的最小内存单元。存储系统会维护一个特殊的数据结构 _页表_，包含了虚拟页到物理页的映射。当一个进程使用它的虚拟地址访问数据时，存储系统就会计算页号（将虚拟地址下除 4096，或者说右移 12 位），然后在页表中查找它的物理地址，将读或写请求转发到实际存储数据的位置。

由于每次内存请求都需要内存转换，同时内存页的编号也有很多（16GB / 4KB = 4M），地址转换本身就是一个难题。一种加速方式是给页表设置一个专用的 cache，translation lookaside buffer (TLB)，另一种是增加页的大小，通过减少页的粒度来减少页的数量。

### 映射到外存

虚拟内存的机制也允许相当直接地使用外部内存类型。现代操作系统支持内存映射，它允许你打开一个文件并使用它的内容，就好像它们在主内存中一样：

```cpp
// open a file containing 1024 random integers for reading and writing
int fd = open("input.bin", O_RDWR);
// map it into memory      size  allow reads and writes  write changes back to the file
int* data = (int*) mmap(0, 4096, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
// sort it like if it was a normal integer array
std::sort(data, data + 1024);
// changes are eventually propagated to the file
```

这里映射了一个 4K 的文件，我们可以用一个内存页保存。但当我们打开一个更大的文件时，读入会在我们需要的时候惰性完成，写入也会被缓冲下来直到需要将页写回（通常是程序终止或者系统没有 RAM 空间了）。

另一种技术有相同的原理，但却有相反的目的，它被称为 _交换文件_。它允许操作系统在没有足够的实际 RAM 时自动使用 SSD 或 HDD 的一部分作为主存的扩展。这让内存空间较小的系统只会经历夸张的减速而不是直接崩溃。

这种主存和外存的无缝集成方式本质上把 RAM 变成了外存的“L4缓存”，从算法设计的角度来看，是一种很便捷的思考方式。

## 三 - 外存模型

为了解释内存瓶颈算法的性能，我们需要一个对块 I/O 操作更加敏感的计算模型。

### 缓存感知模型 (Cache-Aware Model)

在标准 RAM 模型中，我们忽略了基本运算需要不同的时间来完成的这一事实。更重要的是，它没有区分在不同类型存储器上的操作，从 RAM 读取需要 ~50ns，而从 HDD 中读取需要 ~5ms，中间相差了 $10^5$ 倍。

更准确地说，我们考虑 （WIP）
