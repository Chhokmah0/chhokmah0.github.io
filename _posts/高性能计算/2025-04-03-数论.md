---
title: 高性能计算-第七章-数论
date: 2025-4-3 12:00:00 +0800
categories: [笔记, 高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
[原文](https://en.algorithmica.org/hpc/number-theory/)

（嗨嗨嗨，优势区间来了）

## 序 - 数论

在 1940 年，一个英国数学家 G. H. Hardy 出版了一个非常著名的文章《一个数学家的辩白》，讨论了数学应该追求其本身而不是其应用的概念。

和数学一样，计算机科学的各个领域也构成了一个光谱，一边是数理逻辑和计算理论，另一边是网络编程和应用开发。我们假设读者，也就是你，是一个更偏向于应用的计算机科学家。这本书写出来就是为了表明在实际算法设计上的工作比在理论计算机科学上的工作少太多了——既然你读到了第七章，那么你大概率也赞成这个说法。

但是，抛开主观意见不谈，Hardy 的这一观点也有客观因素。在写那篇文章的时候，他已经 62 岁了。他目睹了第一次世界大战和正在进行的第二次世界大战所造成的破坏，而科学在其中造成了更多的破坏。作为一个数论科学家，Hardy 在这种“无用”领域上的工作寻找到了平静，而且不用担心任何道德谴责。

> 到目前为止，还没有人发现数论或相对论可以用于任何军事目的，而且在许多年内，似乎也不太可能有人会这样做。

讽刺的是，随着原子弹的发明，这句话在 5 年后就被证明是错的了。如果没有对相对论的深刻理解，这是不可能达成的。同样的，在数论之上我们也建立起了计算机密码学这一领域——本章的主题便是计算。

## 一 - 模运算

计算机通常使用从 1970.1.1（Unix 时代的开始）后经过的秒数来作为时间戳。

我们人类也会记录与过去某个时间点相关的时间，一般是具有政治或宗教意义的时间点。例如，在撰写本文（指原文）的那一刻，从公元 1 年（公元 6 世纪时东罗马僧侣对耶稣基督出生日期的最佳估计）至今，已经过去大约了 63882260594 秒。

但与电脑不同，我们并不是总是需要所有的信息。考虑到手头上的事情，我们可能会说“现在下午两点了，该吃午饭了。”或者“现在是星期四，v 我 50。”相较于使用整个时间戳，我们更经常使用余数来考虑我们所需要的信息。毕竟处理两位数字比处理十一位数字要简单得多。

**问题**：如果今天是星期四，那么明年的同一个日期是星期几？

我们将一周的日期方式在 $$[0,6]$$ 中，显然这是一个循环的结构。星期四是数字 $$3$$，那么明年的同一日期便是 $$(3 + 365) \bmod 7 = 4$$，也就是星期五。（如果不是闰年的话）

### 余数

**定义**：我们称两个整数 $$a$$ 和 $$b$$ 模 $$m$$ 同余，如果它们的差是 $$m$$ 的倍数：

$$
m | (a-b) \Leftrightarrow a \equiv b \pmod m
$$

比方说，一年的第 42 天和第 161 天的日期就是相同的，$$161 - 42 = 119 = 17 \times 7$$.

模 $$m$$ 同余是一种等价关系，可以将所有整数分成不同的等价类。虽然每一个类都可以使用其中任何一个数字来表示，但我们比较经常使用一个等价类中的最小非负整数来表达这个等价类。

模运算就是在这些等价类上的运算，它是数论的基础。

**问题**：现在，我们定义一“周”有 $$m$$ 天，一“年”有 $$a$$ 天。那么考虑每年的相同日期，它们会遍历一周中的所有星期吗？如果不能，它们包含几个不同的星期？

假设今天是周一，那么 $$d_0 = 0$$，第 $$k$$ 年的星期即为：

$$
d_k \equiv ka \mod m
$$

原问题实际上就是在找出最小的正整数 $$k$$，使得

$$
ka \equiv 0 \pmod m
$$

如果 $$a$$ 和 $$m$$ 互素，那么 $$k$$ 只有等于 $$m$$ 的时候 $$ka$$ 才会是 $$m$$ 的倍数。基于这一思路，我们用 $$(a,m)$$ 表示 $$a$$ 和 $$m$$ 的最大公因数，则有：

$$
\frac{ka}{(a,m)} \equiv 0 \pmod{\frac{m}{(a,m)}}
$$

此时 $$\frac{a}{(a,m)}$$ 和 $$\frac{m}{(a,m)}$$ 是互素的，因此 $$k$$ 的取值为 $$\frac{m}{(a,m)}$$。

### 费马小定理

现在我们考虑如果使用乘法而非加法：

$$
d_n = a^n \mod m
$$

那么序列 $$d_i$$ 中会有多少不重复的值？

**定理**：对于任何整数 $$a$$ 和素数 $$p$$：

$$
a^p \equiv a \pmod p
$$

**证明**：我们用 $$P(x_1,x_2,\dots,x_n) = \frac{(\sum_i x_i)!}{\prod (x_i!)}$$ 来表示多项式系数（多重组合数），那么：

$$
\begin{aligned}
a^p &= (\underbrace{1+1+\dots+1}_{a \text{ times}})^p \\
&= \sum_{\sum_{i} x_i = p} P(x_1,x_2,\dots,x_a) \\
&= P(p,0,\dots,0) + P(0,p,\dots,0) + \dots + P(0,0,\dots,p) \\
&= a \pmod p
\end{aligned}
$$

其中第三个等式是因为 $$p$$ 是一个素数，因此任何小于 $$p$$ 的 $$x_i$$，其阶乘 $$x_i$$ 中都不可能包含因子 $$p$$，所以多重组合数分子上的因子 $$p$$ 会被保留下来，使得整个多重组合数是 $$p$$ 的倍数。只有当 $$P(p,0,\dots,0)$$ 等情况时，因子 $$p$$ 才会被除掉，得到结果 $$1$$。

需要注意的是这一定理只对素数 $$p$$ 成立。反过来，我们可以使用这一定理来检测 $$p$$ 是否为素数：随机选择一个 $$a$$，如果 $$a^p \mod p$$ 不等于 $$a$$，则 $$p$$ 一定不是素数。

这被成为 _费马素性检测_，并且是一个概率算法，只会返回“不是素数”和“可能是素数”。我们可以选取不同的 $$a$$ 直到我们认为犯错的概率足够低。

素性检测可以用来生成大素数（用于密码学）。由于 $$n$$ 以内大约有 $$\frac{n}{\ln n}$$ 个素数（并不打算在这里证明），它们的分布基本是均匀的。因此我们可以随便选一个数，然后不断增加并检测是否是素数，这大约需要 $$O(\ln n)$$ 次素性检测。

费马素性检测的一个非常糟糕的输入是[卡迈克尔数](https://en.wikipedia.org/wiki/Carmichael_number)，它是个费马伪素数，可以完全通过费马素性检测。不过他们非常少见，所以还好。

关于时间复杂性：素性检测实际上是一个 P 问题，对于一个数 $$n$$，由于输入只需要 $$\log n$$ 个 bit 来表示，因此 P 算法必须是关于 $$n$$ 呈现 polylog 的。AKS 素性测试算法便是一个 $$O(\log^8 n) 的一个确定性算法。

### 模意义下的除法

在模意义下，加减乘运算都可以比较直接的进行扩展，只要处理好整数溢出和负数即可。

```cpp
c = (a + b) % m;
c = (a - b + m) % m;
c = a * b % m;
```

但是除法没有这个性质：

$$
\frac{8 \mod 5}{2 \mod 5} = \frac{3}{2} \neq 4
$$

在模意义下，我们会使用乘以逆元的方式来做除法，而逆元即为：

$$
a^p \equiv a \Rightarrow a^{p-2} \equiv a^{-1} \pmod p
$$

因此，$$a^{p-2}$$ 就是 $$a$$ 的逆元。

## 二 - 二进制快速幂

在模运算中，经常需要求一个数的 $$n$$ 次幂。快速幂可以在 $$O(\log n)$$ 的时间内计算一个 $$n$$ 次幂。它只基于以下两个公式：

$$
a^{2k} = (a^{k})^2 \\
a^{2k + 1} = (a^{k})^2 \cdot a
$$

为了计算 $$a^n$$，可以递归计算 $$a^{\lfloor n / 2\rfloor}$$：

$$
a^n = f(a,n) = \left\{
\begin{aligned}
& 1, & n=0 \\
&f(a,\frac{n}{2})^2, & 2 \mid n \\
&f(a,n-1)\cdot a, & 2 \nmid n
\end{aligned}
\right.
$$

由于算法每两次递归都会至少减半，因此算法的深度和乘法的次数都是 $$O(\log n)$$ 的。

### 递归实现

```rust
pub fn binpow_rec<const M:u64>(base: u64, exp: u64) -> u64 {
    match exp {
        0 => 1,
        _ if exp % 2 == 0 => {
            let half = binpow_rec::<M>(base, exp / 2);
            (half * half) % M
        }
        _ => (base % M * binpow_rec::<M>(base, exp - 1)) % M,
    }
}
```

在算法竞赛中，$$M$$ 一般会被设置为 $$10^9 + 7$$。因为它是一个素数（因此所有非零元素都有逆元）、足够大、进行一次加法时不会超出 `int`、进行一次乘法时不会超出 `long long`，并且还可以通过 `1e9 + 7` 来快速输入。

一般我们会将 $$M$$ 设置为编译期常数，这样编译器会将取模运算优化成一个乘法和一个移位操作（详见第六章第七节）。即使没办法在编译期得到模 $$M$$ 时的相关魔法数字，我们也可以手动计算一次它们，然后快速进行除法或取模运算。

baseline 执行 $$2^{10^9} \mod (10^9 + 7)$$ 大约需要 300ns。在这里递归调用产生了一些额外的开销。

### 迭代实现

$$a^n$$ 可以被表示成某些 $$a$$ 的 $$2^i$$ 次幂的乘积，只需要将 $$n$$ 看作是 2 进制就可以很容易的展开，例如：

$$
a^{42} = a^{32 + 8 + 2} = a^{32}a^{8}a^{2}
$$

```rust
pub fn binpow_iter<const M:u64>(mut base: u64, mut exp: u64) -> u64 {
    base %= M;
    let mut result = 1;

    while exp > 0 {
        if exp % 2 == 1 {
            result = (result * base) % M;
        }
        base = (base * base) % M;
        exp /= 2;
    }
    result
}
```

该算法执行 $$2^{10^9} \mod (10^9 + 7)$$ 大约需要 100ns。如果 $$M$$ 不是编译期常数，我也写了一份非编译期的 `binpow` （Lemire Reduction），但这份代码只需要 80ns。可能是由于采用的是自然溢出的方式，少了一次移位操作。

如果 `exp` 是一个常数（例如求逆元时，`exp` 总是 $$M-2$$），虽然理论上编译器可以优化，但是 while 循环往往会阻止编译器优化。我们可以将其重写为 `for` 循环，以促使编译器进行优化。

```cpp
u64 inverse(u64 a) {
    u64 r = 1;
    
    #pragma GCC unroll(30)
    for (int l = 0; l < 30; l++) {
        if ( (M - 2) >> l & 1 )
            r = r * a % M;
        a = a * a % M;
    }

    return r;
}
```

rust 似乎没有显示的循环展开，得要靠宏来实现。这里使用 `seq_macro` 库。

```rust
pub fn inverse<const M: u64>(mut _a: u64) -> u64 {
    let mut result = 1;
    seq_macro::seq!(N in 0..=30 {
        if (M - 2) & (1 << N) != 0 {
            result = (result * _a) % M;
        }
        _a = (_a * _a) % M;
    });
    result
}
```

然而并没有效果。

## 三 - 扩展欧几里得算法

费马定理允许我们在 $$O(\log n)$$ 的时间内求出一个数的逆元，但它只对素数有效。欧拉定理是对费马定理的一个扩展，如果模数 $$m$$ 和数 $$a$$ 是互素的，那么：

$$
    a^{\phi(m)} \equiv 1 \pmod m
$$

### 算法

_扩展欧几里得算法_，可以用于计算 $$g=\gcd(a,b)$$ 以及一对整数 $$x,y$$ 满足：

$$
    ax+by=g
$$

这同时也是裴蜀定理的一个构造性质的证明。

如果我们令其中的 $$b$$ 为 $$m$$，且 $$a$$ 和 $$m$$ 互素，则有：

$$
    a^{-1}a+km=1
$$

其中 $$a^{-1}$$ 和 $$k$$ 是 $$x,y$$，因此我们就得到了一个 $$a$$ 在 $$m$$ 下的逆元 $$a^{-1}$$。

算法本身和 $$\gcd$$ 一样是递归的，我们假设递归得到了一个 $$(b, a \mod b)$$ 下的解 $$(x',y')$$，满足：

$$
bx'+(a \mod b)y' = g
$$

我们有如下推导：

$$
bx'+(a-\left\lfloor\frac{a}{b}\right\rfloor b)y'=g \\
a\underbrace{y'}_x + b \underbrace{(x' - \left\lfloor\frac{a}{b}\right\rfloor y')}_y=g
$$

据此我们构造了一个 $$(a,b)$$ 下的解，因此可以递归解决该问题。

### 实现

我们先实现一个递归版本的代码：

```rust
pub const fn exgcd_rec(a: u64, b: u64) -> (u64, u64, u64) {
    if a == 0 {
        (b, 0, 1)
    } else {
        let (gcd, x1, y1) = exgcd_rec(b % a, a);
        (gcd, y1 - (b / a) * x1, x1)
    }
}
```

此时，我们可以使用如下方式求解逆元：

```rust
pub const fn inverse_exgcd_rec<const M: u64>(a: u64) -> Option<u64> {
    let (gcd, x, _) = exgcd_rec(a, M);
    if gcd == 1 {
        Some((x % M + M) % M)
    } else {
        None
    }
}
```

benchmark 表明这个算法和输入的关系比较大，毕竟递归次数是和 $$\gcd$$ 的递归次数相关。如果用来求 $$2$$ 在 $$10^9+7$$ 下的逆元，9.3ns 就可以求出。而求最坏的输入 $$564400443$$ 在 $$10^9+7$$ 下的逆元需要 348ns。

将其重写为迭代版本（来自 [Wiki](https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm)）：

```rust
pub const fn exgcd_iter(a: i32, b: i32) -> (i32, i32, i32) {
    let (mut old_r, mut r) = (a, b);
    let (mut old_s, mut s) = (1, 0);
    let (mut old_t, mut t) = (0, 1);
    while r != 0 {
        let q = old_r / r;
        old_r -= q * r;
        old_s -= q * s;
        old_t -= q * t;
        std::mem::swap(&mut old_r, &mut r);
        std::mem::swap(&mut old_s, &mut s);
        std::mem::swap(&mut old_t, &mut t);
        // let (new_r, new_s, new_t) = (old_r - q * r, old_s - q * s, old_t - q * t);
        // (old_r, r) = (r, new_r);
        // (old_s, s) = (s, new_s);
        // (old_t, t) = (t, new_t);
    }
    (old_r, old_s, old_t)
}

pub const fn inverse_exgcd_iter<const M: i32>(a: i32) -> Option<i32> {
    let (mut old_r, mut r) = (M, a);
    let (mut old_t, mut t) = (0, 1);

    while r > 1 {
        let q = old_r / r;
        old_r -= q * r;
        old_t -= q * t;
        std::mem::swap(&mut r, &mut old_r);
        std::mem::swap(&mut t, &mut old_t);
        // let (new_r, new_t) = (old_r - q * r, old_t - q * t);
        // (old_r, r) = (r, new_r);
        // (old_t, t) = (t, new_t);
    }
    if r == 1 {
        if t < 0 {
            t += M;
        }
        Some(t)
    } else {
        None
    }
}
```

此时求最坏的输入 $$564400443$$ 在 $$10^9+7$$ 下的逆元需要 130.82ns。

[Wiki](https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm) 中表明当 $$a,b$$ 都是正数且 $$\gcd(a,b) \neq \min(a,b)$$ 时，算法过程中产生的 $$\lvert s_i\rvert$$ 和 $$\lvert t_i\rvert$$ 分别都不大于 $$\lfloor \lvert b \rvert / (2\gcd(a,b)) \rfloor$$ 和 $$\lfloor \lvert a\rvert / (2\gcd(a,b)) \rfloor$$。

当 $$\gcd(a,b) = \min(a,b)$$ 时，算法在两轮内结束，且最后的输出是 $$(0,1)$$ 或 $$(1,0)$$。只是在中间的计算过程中会到达 $$\pm \lvert b\rvert / \gcd(a,b)$$ 和 $$\pm \lvert a\rvert / \gcd(a,b)$$ 边界。

## 四 - 蒙哥马利算法 (Montgomery Multiplication)

显然，模算数当中很多时间都被花费在取模运算上了。它和除法指令一样慢，根据操作数的大小，可能需要花费 15-20 个时钟周期。

处理这些麻烦的最好的方法就是避免模运算，把它尽可能延后，或者用加减法来代替。例如，我们可以用这这两种方式来求和：

```rust
pub fn slow_sum<const M: i32>(a: Vec<i32>) -> i32 {
    let mut sum = 0;
    for val in a {
        sum += val;
        sum %= M;
    }
    sum
}

pub fn fast_sum<const M: i32>(a: Vec<i32>) -> i32 {
    let mut sum = 0;
    for val in a {
        sum += val;
        if sum >= M {
            sum -= M;
        }
    }
    sum
}

pub fn faster_sum<const M: i32>(a: Vec<i32>) -> i32 {
    let mut sum = 0i64;
    for val in a {
        sum += val as i64;
    }
    (sum % M as i64) as i32
}
```

让他们计算 $$[1,2,3,4,5,6,7,8,9,10]$$ 的和分别花费 32.4ns, 19.8ns 和 16.6ns。

但有些时候你需要计算一长串的模乘法，这个时候就没有什么好方法避免除法了——不过你还是可以用整数除法的优化方式将其优化成一个乘法和一个移位操作。

这里还有另一个用于模运算的技术，称之为 _蒙哥马利算法 (Montgomery multiplication)_。

### 蒙哥马利空间

蒙哥马利算法的主要思路是将乘数转换到蒙哥马利空间，在那里可以快速地执行模乘法，最后再将结果转换回来。和一般的对整数除法的优化不同，蒙哥马利算法只对多次链式的模乘法有比较好的加速效果。

假设我们在模 $$n$$ 空间下，以及一个和 $$n$$ 互素的正整数 $$r \geq n$$。在实际中，$$r$$ 经常被选为 $$2^{32}$$ 或者 $$2^{64}$$，这样就可以用右移和与运算操作来计算乘法。

**定义**。我们定义 $$x$$ 在蒙哥马利空间中的表示 $$\bar{x}$$ 为：

$$
\bar{x} = xr \mod n
$$

计算这个表示就需要一个取模运算——我们原本想要节省的运算——这也是为什么我们只把它用于链式乘法。

在蒙哥马利空间里，加法和减法还是照常进行的（但是还是需要对 $$n$$ 取模，不过加法的增量比较低，所以可以将取模操作延后）：

$$
\begin{aligned}
xr+yr \equiv (x+y)r \mod n \\
\bar{x} + \bar{y} \equiv \overline{x+y} \mod n
\end{aligned}
$$

但是乘法并不是这样的：

$$
\begin{aligned}
\bar{x}\bar{y} \equiv (xy)rr \mod n \\
\bar{x}\bar{y}\cdot r^{-1} \equiv \overline{xy} \mod n
\end{aligned}
$$

我们需要乘以 $$r$$ 的逆元并取模才能得到蒙哥马利空间下的乘法——而我们有一个足够快的方法来做这件事。

### 蒙哥马利归约

假设 $$r=2^{32}$$，这意味着模数 $$n$$ 也是 32 位的，而我们所需要归约的数字 $$x$$ 是 64 位的（两个 32 位数字的乘积）。我们的目标是计算 $$y = x r^{-1} \mod n$$。

由于 $$r$$ 和 $$n$$ 是互素的，我们可以通过扩展欧几里得算法得到 $$r^{-1}$$ 和 $$n'$$ 满足：

$$
rr^{-1} + nn' = 1
$$

因此我们有如下推导：

$$
\begin{aligned}
xr^{-1} &= \frac{xrr^{-1}}{r} \\
&= \frac{x(1-nn')}{r} \\
&= \frac{x-xnn'}{r}\\
&\equiv \frac{x-xnn'+krn}{r} \pmod n\\
&\equiv \frac{x-(xn'-kr)n}{r} \pmod n
\end{aligned}
$$

如果我们选取 $$k=\left\lfloor \frac{xn'}{r} \right\rfloor$$，此时 $$xn'-kr = xn' \mod r$$ （模运算的性质），则：

$$
xr^{-1} \equiv \frac{x - (xn' \mod r)n}{r} \pmod n
$$

由于 $$r$$ 是 $$2$$ 的幂次，因此我们可以通过与运算和移位运算来计算取模和除法。

唯一的问题是最后的 $$\mod n$$ 怎么处理。我们可以证明这个结果一定会落在 $$(-n,n)$$ 中。

$$
0 < \frac{x}{r} < \frac{n^2}{r} < \frac{nr}{r} = n
$$

以及

$$
0 < \frac{(xn' \mod r)n}{r} < \frac{rn}{r} < n
$$

我们可以知道最后做减法的结果一定是落在 $$(-n,n)$$ 之间。因此只需要快速检查一下是否落在负数，如果是，则 $$+n$$。如果你不介意落到 $$[0,2*n - 2]$$ 之间，也可以去除条件分支语句直接 $$+n$$（此时 $$x*x$$ 乘法会到达 $$4n^2$$ 的上界）。

另外，我们还可以用 $$\lfloor \frac{x}{r} \rfloor - \lfloor\frac{(xn' \mod r)n}{r} \rfloor$$ 来代替先减后除，这样做的好处是 u32 乘 u32 后取高 32 位这一操作可以被优化，例如 x86 的 `mul` 指令会将这个结果放到一个独立的寄存器里。

蒙哥马利算法和其他的缩减算法相比，它的优势在于它不需要很大的数据类型：只需要计算 $$r\times r$$ 后取高于或者低于 $$r$$ 的所有 bits，这在许多硬件上都有支持，并且很容易将其推广到 SIMD 或者更大的数据类型。

在模数是 64 位的情况下，一般的规约方法可能无法避免真的使用 u128 来表示数据。而蒙哥马利算法则仍然可以使用 u64 上的乘法（u64 乘 u64 的结果会被放到两个 64 位寄存器上，可以得到高位和低位的结果）。

### 快速转换

蒙哥马利算法中存在三个转换过程：

- 计算 $$n$$ 在 $$r$$ 下的逆元 $$n'$$。
- 将一个数字转化到蒙哥马利空间。
- 从蒙哥马利空间还原一个数字。

第三步可以通过之前的归约过程实现，毕竟其本质上是在求一个数字乘 $$r^{-1}$$ 后模 $$n$$ 的结果。而第一第二步也可以有一点优化。

#### 快速计算逆元 $$n' = n^{-1} \mod r$$

我们可以利用数字 $$r$$ 是 $$2^{2^k}$$ 次幂的这一特点，用类似于牛顿迭代法的方式求出 $$n$$ 的逆元。考虑如下结果：

$$
x \equiv 1 \pmod{2^{k}} \Rightarrow x(2-x) \equiv 1 \pmod{2^{2k}}
$$

证明如下：

$$
\begin{aligned}
x(2-x) &= 2x-x^2 \\
&= 2(1+m2^k) - (1+m2^k)^2 \\
&= 2 + 2m2^k-1-2m2^k+m^22^{2k} \\
&= 1-m^22^{2k} \\
&= 1 \pmod{2^{2k}}
\end{aligned}
$$

因此，我们可以从 $$x=1$$ 开始，$$nx = 1 \pmod{2^1}$$，每次令 $$x \gets x(2-nx)$$ 即可。由于 $$r$$ 是二的幂次，因此直接让乘法、加减法自然溢出就好。这个算法会在 $$\log_2 \log_2 r$$ 步后结束。

#### 快速转换到蒙哥马利空间

相较于计算 $$xr \mod n$$，我们也可以假装 $$x$$ 已经在蒙哥马利空间内，然后在蒙哥马利空间内和 $$r^2 \mod n$$ 相乘（蒙哥马利空间内的乘法会额外计算乘 $$r^{-1} \mod n$$ 后的结果），这样就得到了 $$xr \mod n$$。

不过这一方法有可能变快也可能变慢，虽然减少了一个取模运算，但是原本乘以 $$r=2^{k}$$ 可以通过左移来实现，而乘以 $$r^2 \mod n$$ 却不能。

### 完整实现

完整的实现如下：

```rust
#[derive(Debug, Clone, Copy)]
pub struct Montgomery {
    n: u32,
    inv_n: u32,
    sqr_r: u32,
}
#[derive(Debug, Clone, Copy)]
pub struct MontgomerySpace {
    x: u32,
}

impl Montgomery {
    #[inline]
    /// create a new Montgomery instance
    /// `n` must be coprime to 2^32
    /// i32 make x + x will not exceed 2^32
    pub const fn new(n: i32) -> Self {
        if n % 2 == 0 {
            panic!("n is not coprime to 2^32");
        }
        let n = n as u32;
        let mut inv_n = 1u32; // 2^1
        inv_n = inv_n.wrapping_mul(2u32.wrapping_sub(n.wrapping_mul(inv_n))); // 2^2
        inv_n = inv_n.wrapping_mul(2u32.wrapping_sub(n.wrapping_mul(inv_n))); // 2^4
        inv_n = inv_n.wrapping_mul(2u32.wrapping_sub(n.wrapping_mul(inv_n))); // 2^8
        inv_n = inv_n.wrapping_mul(2u32.wrapping_sub(n.wrapping_mul(inv_n))); // 2^16
        inv_n = inv_n.wrapping_mul(2u32.wrapping_sub(n.wrapping_mul(inv_n))); // 2^32
        // compute (1 << 64) % n, result is in [1, n]
        let sqr_r = (0xffff_ffff_ffff_ffffu64 % n as u64) as u32 + 1;
        Montgomery { n, inv_n, sqr_r }
    }

    #[inline]
    /// times r^(-1) (mod n)
    /// returns a number in the [0, 2 * n - 2] range
    fn reduce(&self, x: u64) -> MontgomerySpace {
        let q = (x as u32 as u64 * self.inv_n as u64) as u32; // x * n^(-1) mod R
        let m = ((q as u64 * self.n as u64) >> 32) as u32; // q * n / R
        // returns a number in the [0, 2 * n - 2] range
        MontgomerySpace {
            x: (x >> 32) as u32 + (self.n - m),
        }
    }

    /// convert montgomery space to normal space
    /// returns a number in the (0, n] range
    #[inline]
    pub fn from(&self, m: MontgomerySpace) -> u32 {
        self.reduce(m.x as u64).x
    }

    /// convert normal space to montgomery space
    #[inline]
    pub fn to(&self, x: u32) -> MontgomerySpace {
        // let mut x = ((x as i64) * self.r as i64) % self.n as i64;
        // if x < 0 {
        //     x += self.n as i64;
        // }
        // MontgomerySpace { x: x as u32 }
        // or
        self.reduce(x as u64 * self.sqr_r as u64)
    }

    /// multiply two numbers in montgomery space
    #[inline]
    pub fn mul(&self, lhs: MontgomerySpace, rhs: MontgomerySpace) -> MontgomerySpace {
        let x = lhs.x as u64 * rhs.x as u64;
        self.reduce(x)
    }
}

pub fn inverse_using_montgomery(base: i32, mod_val: i32) -> i32 {
    let montgomery = Montgomery::new(mod_val);
    let mut result = montgomery.to(1);
    let mut base = montgomery.to(base as u32);
    let mut exp = mod_val - 2;

    while exp > 0 {
        if exp & 1 == 1 {
            result = montgomery.mul(result, base);
        }
        base = montgomery.mul(base, base);
        exp >>= 1;
    }
    montgomery.from(result) as i32
}

pub fn inverse_with_montgomery(base: i32, montgomery: &Montgomery) -> i32 {
    let mut result = montgomery.to(1);
    let mut base = montgomery.to(base as u32);
    let mut exp = montgomery.n - 2;

    while exp > 0 {
        if exp & 1 == 1 {
            result = montgomery.mul(result, base);
        }
        base = montgomery.mul(base, base);
        exp >>= 1;
    }
    montgomery.from(result) as i32
}
```

包含构造 Montgomery 的快速幂需要花费 125ns，不包括的需要花费 119ns。快于普通的快速幂 180ns，慢于编译期常数优化的快速幂 100ns，慢于 lemire_reduction 的 80ns。
