---
title: 高性能计算-第十章-SIMD
date: 2025-6-24 12:00:00 +0800
categories: [笔记, 高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
[原文](https://en.algorithmica.org/hpc/simd/)

## 序

考虑如下程序，我们计算一个整数数组的所有数之和：

```rust
pub fn sum(a: &[i32]) -> i32 {
    let mut result = 0;
    for &x in a {
        result += x;
    }
    result
}
```

使用 cargo 在 release 模式下编译后，这个函数计算 $10^6$ 个数之和的时间为 127μs。而在全局变量中指定了 CPU 允许 `avx2` 特性后 (`RUSTFLAGS="-C target-cpu=haswell"`)，所需要的时间变为 116μs。

> 原文中使用 c++，并在这里产生了两倍加速。尚不清楚原因。
{: .prompt-warning }

我们给编译器额外提供了一些最终程序会运行在什么机器上的信息。具体来说，我们告诉编译器我们会在支持 `AVX2` 的 CPU 上运行程序。其中 `AVX2` 是 x86 的一个扩展指令集，也是 x86 的众多所谓的 “SIMD 扩展” 中的一个。这些扩展包含了一些指令，它们可以使用 128、256、512 bits 的特殊寄存器并执行“单指令，多数据”的流程。SIMD 指令并不是一个值一个值处理，而是将寄存器分割成 8、16、32 或者 64 比特大小的块，然后并行地对它们进行相同的处理，从而提高运行效率[^heavy]。

这些扩展相对较新，因此它们一般是逐渐加入 CPU 并维护向后兼容性的[^backward]。除了增加了一些特殊指令外，更重要的是增加了对更宽的数据的支持。

例如，AVX2 具有使用 256 位寄存器的指令。而在默认情况下，GCC 假定 CPU 上没有比支持 128 位的 SSE2 更新的指令集。因此，在告诉优化器它可以使用一次对 8 个整数做加法而不是 4 个整数的指令后，性能提高了两倍。

![intel](/assets/simd/intel-extensions.webp)

一般而言编译器都可以很好的使用 SIMD 指令重写简单循环，比如之前的例子。这种优化被称作自动向量化，也是 SIMD 最常用的使用方式。

而问题在于，这样的自动向量化只适用于某些类型的循环，即使这样，产生的最终程序也往往不是最优而是次优的。为了理解编译器的极限，我们得自己上手探索这个技术在底层的情况。

[^heavy]: 在某些 CPU 上，SIMD 特别是更重的 SIMD 指令会消耗更多的能量，导致 CPU 需要降频来平衡总体的电力消耗，所以实际的加速并不总是成比例的。

[^backward]: 从 `AVX512` 起开始不再维护向后兼容性：针对数据压缩、加密、机器学习等特殊需求会产生不同的设计。

## 一 - 内置函数和向量类型

使用 SIMD 的最低层次的方法是直接使用汇编的向量指令——使用它们和使用它们的标准版本在方式上并没有什么区别。不过我们并不在这一章使用这种方法，而是使用现代编译器所提供的 _内置函数 (intrinsic functions)_。

### 准备

要使用 x86 的内置，我们需要做一些基础工作。

首先，我们得确认自己的硬件支持哪些扩展。在 Linux 上，我们可以调用 `cat /proc/cpuinfo`，而在其他平台上，最好是到 [WikiChip](https://en.wikichip.org/wiki/WikiChip) 上查找。

还有一个特殊的 `CPUID` 汇编指令，它允许查询有关 CPU 的各种信息，包括对特定向量扩展的支持。`CPUID` 经常被用于在运行时获取 CPU 信息，这样就不需要对各种不同的架构发布不同的二进制文件。它的输出信息以特征掩码的形式非常密集地存储，因此编译器提供了一些内置方法来理解它。下面是一个例子：

```rust
use std::arch;

fn main() {
    println!("Checking CPU support for SIMD instructions...");
    println!("SSE: {}", arch::is_x86_feature_detected!("sse"));
    println!("SSE2: {}", arch::is_x86_feature_detected!("sse2"));
    println!("AVX: {}", arch::is_x86_feature_detected!("avx"));
    println!("AVX2: {}", arch::is_x86_feature_detected!("avx2"));
    println!("AVX512: {}", arch::is_x86_feature_detected!("avx512f"));
}
```

在 rust 中，我们需要从 `std::arch` 中找出自己的目标架构，从而引入相应的函数。

最后，我们需要告诉编译器我们会将二进制文件运行在目标平台上。在 rust 中会使用 `#[cfg(target_arch = "x86_64")]`，从而仅在指定的平台上编译相应的代码。随后使用 `if cfg!(target_arch = "x86_64") {...} else {...}` 可以在特定的平台上运行相应的代码。

在本章中我们重点关注 AVX2 以及之前的 SIMD 扩展，它们可以在 95% 的电脑上运行。

### SIMD 寄存器

SIMD 扩展中最值得注意的版本是那些扩展了寄存器大小的版本：

- SSE (1999) 增加了 16 个 128 比特寄存器，从 `xmm0` 编号到 `xmm15`；
- AVX (2011) 增加了 16 个 256 比特寄存器，从 `ymm0` 编号到 `ymm15`；
- AVX512 (2017) 增加了[^AVX512] 16 个 512 比特寄存器，从 `zmm0` 编号到 `zmm15`。

[^AVX512]: AVX512 还增加了 8 个被叫做掩码寄存器的东西，从 `k0` 到 `k7`，用于遮罩和混合数据。而本文重点介绍 AVX2 及其之前的版本，因此不会包含这一部分。

从命名 (512) 和 512 位数据已经占满了整个缓存行来看，x86 架构的设计者近期并不打算再次增大寄存器。

