---
title: 高性能计算-第十章-SIMD
date: 2025-6-24 12:00:00 +0800
categories: [笔记, 高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
[原文](https://en.algorithmica.org/hpc/simd/)

## 序

考虑如下程序，我们计算一个整数数组的所有数之和：

```rust
pub fn sum(a: &[i32]) -> i32 {
    let mut result = 0;
    for &x in a {
        result += x;
    }
    result
}
```

使用 cargo 在 release 模式下编译后，这个函数计算 $$10^6$$ 个数之和的时间为 127μs。而在全局变量中指定了 CPU 允许 `avx2` 特性后 (`RUSTFLAGS="-C target-cpu=haswell"`)，所需要的时间变为 116μs。

> 原文中使用 c++，并在这里产生了两倍加速。尚不清楚原因。
{: .prompt-warning }

我们给编译器额外提供了一些最终程序会运行在什么机器上的信息。具体来说，我们告诉编译器我们会在支持 `AVX2` 的 CPU 上运行程序。其中 `AVX2` 是 x86 的一个扩展指令集，也是 x86 的众多所谓的 “SIMD 扩展” 中的一个。这些扩展包含了一些指令，它们可以使用 128、256、512 bits 的特殊寄存器并执行“单指令，多数据”的流程。SIMD 指令并不是一个值一个值处理，而是将寄存器分割成 8、16、32 或者 64 比特大小的块，然后并行地对它们进行相同的处理，从而提高运行效率[^heavy]。

这些扩展相对较新，因此它们一般是逐渐加入 CPU 并维护向后兼容性的[^backward]。除了增加了一些特殊指令外，更重要的是增加了对更宽的数据的支持。

例如，AVX2 具有使用 256 位寄存器的指令。而在默认情况下，GCC 假定 CPU 上没有比支持 128 位的 SSE2 更新的指令集。因此，在告诉优化器它可以使用一次对 8 个整数做加法而不是 4 个整数的指令后，性能提高了两倍。

![intel](/assets/simd/intel-extensions.webp)

一般而言编译器都可以很好的使用 SIMD 指令重写简单循环，比如之前的例子。这种优化被称作自动向量化，也是 SIMD 最常用的使用方式。

而问题在于，这样的自动向量化只适用于某些类型的循环，即使这样，产生的最终程序也往往不是最优而是次优的。为了理解编译器的极限，我们得自己上手探索这个技术在底层的情况。

[^heavy]: 在某些 CPU 上，SIMD 特别是更重的 SIMD 指令会消耗更多的能量，导致 CPU 需要降频来平衡总体的电力消耗，所以实际的加速并不总是成比例的。

[^backward]: 从 `AVX512` 起开始不再维护向后兼容性：针对数据压缩、加密、机器学习等特殊需求会产生不同的设计。

## 一 - 内置函数和向量类型

使用 SIMD 的最低层次的方法是直接使用汇编的向量指令——使用它们和使用它们的标准版本在方式上并没有什么区别。不过我们并不在这一章使用这种方法，而是使用现代编译器所提供的 _内置函数 (intrinsic functions)_。

### 准备

要使用 x86 的内置，我们需要做一些基础工作。

首先，我们得确认自己的硬件支持哪些扩展。在 Linux 上，我们可以调用 `cat /proc/cpuinfo`，而在其他平台上，最好是到 [WikiChip](https://en.wikichip.org/wiki/WikiChip) 上查找。

还有一个特殊的 `CPUID` 汇编指令，它允许查询有关 CPU 的各种信息，包括对特定向量扩展的支持。`CPUID` 经常被用于在运行时获取 CPU 信息，这样就不需要对各种不同的架构发布不同的二进制文件。它的输出信息以特征掩码的形式非常密集地存储，因此编译器提供了一些内置方法来理解它。下面是一个例子：

```rust
use std::arch;

fn main() {
    println!("Checking CPU support for SIMD instructions...");
    println!("SSE: {}", arch::is_x86_feature_detected!("sse"));
    println!("SSE2: {}", arch::is_x86_feature_detected!("sse2"));
    println!("AVX: {}", arch::is_x86_feature_detected!("avx"));
    println!("AVX2: {}", arch::is_x86_feature_detected!("avx2"));
    println!("AVX512: {}", arch::is_x86_feature_detected!("avx512f"));
}
```

在 rust 中，我们需要从 `std::arch` 中找出自己的目标架构，从而引入相应的函数。

最后，我们需要告诉编译器我们会将二进制文件运行在目标平台上。在 rust 中会使用 `#[cfg(target_arch = "x86_64")]`，从而仅在指定的平台上编译相应的代码。随后使用 `if cfg!(target_arch = "x86_64") {...} else {...}` 可以在特定的平台上运行相应的代码。

在本章中我们重点关注 AVX2 以及之前的 SIMD 扩展，它们可以在 95% 的电脑上运行。

### SIMD 寄存器

SIMD 扩展中最值得注意的版本是那些扩展了寄存器大小的版本：

- SSE (1999) 增加了 16 个 128 比特寄存器，从 `xmm0` 编号到 `xmm15`；
- AVX (2011) 增加了 16 个 256 比特寄存器，从 `ymm0` 编号到 `ymm15`；
- AVX512 (2017) 增加了[^AVX512] 16 个 512 比特寄存器，从 `zmm0` 编号到 `zmm15`。

[^AVX512]: AVX512 还增加了 8 个被叫做掩码寄存器的东西，从 `k0` 到 `k7`，用于遮罩和混合数据。而本文重点介绍 AVX2 及其之前的版本，因此不会包含这一部分。

从命名 (512) 和 512 位数据已经占满了整个缓存行来看，x86 架构的设计者近期并不打算再次增大寄存器。

C/C++ 编译器会使用一些特殊的向量类型来表示数据存储在这些特殊的寄存器中：

- 128 位的 `__m128`, `__m128d` 和 `__m128i` 分别使用于单精度浮点数，双精度浮点数和不同的整数类型；
- 256 位的 `__m256`, `__m256d` 和 `__m256i`；
- 512 位的 `__m512`, `__m512d` 和 `__m512i`。

寄存器中其实可以存储任何种类的数据，上面的类型只是用于类型检查。事实上，你可以直接将一个向量变量转化为其它向量类型，就像是你转换其它基本数据类型，这基本不会产生开销。

### SIMD 内建函数（内在函数、内部函数？）

编译器内建函数是一些 C 语言风格的函数，一般都是简单的调取一些相关的汇编指令来实现。

例如，我们可以使用 AVX 内建函数对两个 64 位浮点数的数组进行求和：

```rust
pub fn simd_add(a: &[f64], b: &[f64], c: &mut [f64]) {
    assert!(a.len() == b.len() && a.len() == c.len());
    let chunk_size = 4; // Number of f64 values processed in one SIMD operation
    let len = a.len();
    let simd_chunks = len / chunk_size * chunk_size;

    unsafe {
        for i in (0..simd_chunks).step_by(chunk_size) {
            let a_vec = arch::x86_64::_mm256_loadu_pd(a.as_ptr().add(i));
            let b_vec = arch::x86_64::_mm256_loadu_pd(b.as_ptr().add(i));
            let c_vec = arch::x86_64::_mm256_add_pd(a_vec, b_vec);
            arch::x86_64::_mm256_storeu_pd(c.as_mut_ptr().add(i), c_vec);
        }
    }

    // Handle remaining elements
    for i in simd_chunks..len {
        c[i] = a[i] + b[i];
    }
}
```

> 在实验中，该 `simd_sum` 求和 $$10^7$$ 个 64 位浮点数所需的时间为 19ms，而简单实现的 `sum` 则只需要 15ms。可能是编译器优化的太好了？但是在 `cargo-show-asm` 中并没有很明显的看到使用 SIMD 指令集。
{: .prompt-warning }
> 是的。在 `simd_sum` 中，rust 编译的结果产生了四个 call 指令调用对应的函数。而 `sum` 中，rust 编译时进行了 simd 优化，且如后文所说，只使用了三条向量指令。
{: .prompt-tip }
> rust 如果想要使用 AVX 指令集（256 位），需要指定 `--target-cpu=x86-64-v3`。而默认的选项是 `--target-cpu=x86-64`，这导致其只能使用 128 位的寄存器。修改 `target-cpu` 后，两者的速度都基本是 14.5ms。顺便一提，在每 4 个浮点数相加的情况下，编译器仍然对两个函数都做了循环展开优化。
{: .prompt-tip }
> 之前的某个章节其实提到过 `target-cpu=native` 表示本机编译本机运行，可以自动根据当前 cpu 进行优化来着，忘了这一点了。
{: .prompt-tip }

使用 SIMD 最主要的挑战之一是将数据切分为固定大小的块放入寄存器中。一般有两种解决方案：

- 给最后一些部分填充一些不会影响计算结果的数据，例如上述代码中应该给最后填 0。
- 留出最后一部分数据，用平常的方式计算它们。

### 指令引用

大多数 SIMD 指令的命名都是 `_mm<size>_<action>_<type>` 这种样子，并且对应于一个长得差不多的汇编指令。在习惯了这些命名后就能一眼看出来这个指令是做什么，但是还是有一些指令看上去是小猫踩到键盘上才出来的。（试着破译一下：`punpcklqdq`）

这里有一些更多的例子：

- `_mm_add_epi16`：将两个 128 位向量看作 16 位扩展打包整数 (extended packed integers) 相加。
- `_mm256_acos_pd`：计算 4 个打包 double 的 $$\arccos$$ 值。
- `_mm256_broadcast_sd`：广播（复制） 1 个 double 到结果向量中的 4 个元素。
- `_mm256_ceil_pd`：将 4 个 double 向上取整。
- `_mm256_cmpeq_epi32`：比较 2 个 256 位向量，每个向量有 $$256/32=8$$ 个整数，返回一个掩码，其中 1 表示对应的两个整数相等。
- `_mm256_blendv_ps`：根据传入的掩码获取对应的单精度浮点数。

你可能感觉到这里有非常多数量的内建函数，除此之外，有一些指令还包含立即数——因此这些内建函数需要编译期常数：例如，浮点数比较的指令有 32 个版本。

出于某些原因，有些操作对寄存器中存储的数据类型无特定要求，但仅支持特定向量类型（通常是 32 位浮点数）——若要使用这类内建函数，只需进行数据类型的转换即可。为简化本章示例，我们将主要使用 256 位 AVX2 寄存器中的32位整数 (epi32)。

x86 SIMD 内建函数的一个极佳参考是[《Intel 内建函数指南》](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)，该指南按类别和扩展集进行分类，包含功能描述、伪代码、对应汇编指令及其在英特尔微架构上的延迟与吞吐量数据。建议你将这个页面添加至书签。

当你确认某条特定指令存在，仅需查询其名称或性能信息时，英特尔参考手册非常实用。若不确定所需指令是否存在，这份[速查表](https://db.in.tum.de/~finis/x86%20intrinsics%20cheat%20sheet%20v1.0.pdf)或许能更高效地满足需求。

**指令选择**。注意编译器并不一定会选择你想要的特定指令。类似于我们之前讨论的标量加法并赋值 $$c = a + b$$，这里也有一个融合的向量加法指令。所以编译器并不是使用我们写的每个循环周期 $$2+1+1=4$$ 个指令，而是用 $$3$$ 个指令块重写上面的代码，[像这样](https://godbolt.org/z/dMz8E5Ye8)：

```nasm
vmovapd ymm1, YMMWORD PTR a[rax]
vaddpd  ymm0, ymm1, YMMWORD PTR b[rax]
vmovapd YMMWORD PTR c[rax], ymm0
```

有时候（虽然很少），这种编译器的行为会使事情变得更糟。所以仔细检查程序集并检查使用的向量指令总是一个好主意（AVX 指令通常以“v”开头，或者你可以查看寄存器的命名是否为 `*mm` 来判断是不是 SIMD）。

此外，一些内建函数也并不对应于单个指令，例如 broadcasts 和 extracts，会对应一小串指令。

### GCC 向量扩展

如果你觉得 C 语言的内建指令非常混乱，那你不是一个人。原作者花了几百个小时在写 SIMD 代码和阅读《Intel 内建函数指南》上，但是他还是不知道自己是要输入 `_mm256` 还是 `__m256`。

内建函数即难用，而且可移植性和可维护性也很差。在优秀的软件中，开发者并不希望为每款 CPU 维护不同的程序；而是希望以与架构无关的方式，仅实现一次即可。

有一天，GNU 项目的编译器工程师也产生了同样的想法，并研发出一种方法——允许用户定义专属的向量类型。这种类型使用起来更接近数组，且部分运算符经过重载，可匹配相关指令。

在 GCC 中，定义一个 “包含 8 个整数、打包存储在 256 位（32 字节）寄存器中” 的向量，方式如下：

```cpp
typedef int v8si __attribute__ (( vector_size(32) ));
// type ^   ^ typename          size in bytes ^ 
```

遗憾的是，这并非 C 或 C++ 标准的一部分，因此不同编译器会采用不同的语法来实现这一功能。

这里只存在一种大致的命名约定，即把元素的数量和类型纳入类型名称中：在上面的示例里，我们定义的是 “8 个有符号整数组成的向量”。不过你也可以自行选择任意名称，比如 vec、reg 之类均可。唯一需要避免的是将其命名为 vector——因为这会与 `std::vector` 造成极大混淆。

使用这种类型的主要优势在于，对于多数操作，你无需查阅对应的内置函数，直接使用常规的 C++ 运算符即可完成。

```cpp
v4si a = {1, 2, 3, 5};
v4si b = {8, 13, 21, 34};

v4si c = a + b;

for (int i = 0; i < 4; i++)
    printf("%d\n", c[i]);

c *= 2; // multiply by scalar

for (int i = 0; i < 4; i++)
    printf("%d\n", c[i]);
```

使用向量类型，我们可以极大地简化之前使用内建函数实现的 “a + b” 循环：

```cpp
typedef double v4d __attribute__ (( vector_size(32) ));
v4d a[100/4], b[100/4], c[100/4];

for (int i = 0; i < 100/4; i++)
    c[i] = a[i] + b[i];
```

如你所见，相较于内置函数带来的混乱局面，向量扩展的用法要简洁得多。但它也存在缺点：有些我们想要实现的功能，仅通过原生 C++ 的向量扩展是无法表达的，因此仍需借助内置函数来完成。幸运的是，这并非非此即彼的选择——因为向量类型与 `_mm` 系列类型可以进行零成本转换：

```cpp
v8f x;
int mask = _mm256_movemask_ps((__m256) x)
```

这里 `(__m256) x` 就是在类型转换。

此外，还有许多适用于不同语言的第三方库，它们不仅能提供类似的可移植 SIMD 代码编写能力，还实现了部分常用功能，且总体使用体验比内建函数和编译器内置向量类型都更友好。C++ 领域中值得关注的例子包括 Highway、Expressive Vector Engine、Vector Class Library 以及 xsimd。另外，c++26 中打算加入 `std::simd`，rust 的 `std::simd` 则到目前为止仍是实验性功能。

建议使用成熟的 SIMD 库，因为它能显著提升开发体验。不过，本书将尽量贴近硬件底层，主要直接使用内建函数；仅在条件允许且为了简化代码的情况下，偶尔切换到向量扩展。

## 二 - 移动数据

如果你查看了[参考文献](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)，你会注意到所有的向量操作本质上有两种：

1. 对向量的元素执行某些操作的指令（`+`，`*`，`<` 等）；
2. 加载、存储、掩码、打乱和移动数据的指令。

使用逐元素指令虽然简单，但 SIMD 面临的最大挑战在于如何高效地将数据载入向量寄存器——这需要足够低的开销，才能确保整个优化过程具有实际价值。

### 对齐加载和存储

将数据读写到 SIMD 寄存器的指令都有两个版本 `load`/`loadu` 和 `store`/`storeu`。这里的 u 表示 unaligned。 前一种版本只有在读写同一缓存行的数据时才会正常执行，而后一种在任何情况下都可以正确执行，只是有时会损失一点性能。

但是当内部操作非常轻量的时候，不同版本的性能差异就开始变得显著（因为每次计算都需要获取两次缓存行）。例如，将两个数组进行求和：

```rust
for i in (0..simd_chunks).step_by(chunk_size) {
    let a_vec = arch::x86_64::_mm256_loadu_pd(a.as_ptr().add(i));
    let b_vec = arch::x86_64::_mm256_loadu_pd(b.as_ptr().add(i));
    let c_vec = arch::x86_64::_mm256_add_pd(a_vec, b_vec);
    arch::x86_64::_mm256_storeu_pd(c.as_mut_ptr().add(i), c_vec);
}
```

在有时，相较于 aligned 版本会慢个 ~30%：

```rust
for i in (0..simd_chunks).step_by(chunk_size) {
    let a_vec = arch::x86_64::_mm256_load_pd(a.as_ptr().add(i));
    let b_vec = arch::x86_64::_mm256_load_pd(b.as_ptr().add(i));
    let c_vec = arch::x86_64::_mm256_add_pd(a_vec, b_vec);
    arch::x86_64::_mm256_store_pd(c.as_mut_ptr().add(i), c_vec);
}
```

在第一个版本中，倘若数组没有对齐，由于一个缓存行是 512 比特，这使得有一半的读写都是“坏的”，会占用更多的时间。

需要注意的是，这种性能差异是由缓存系统而非指令本身导致的。在大多数仙丹处理器上，`loadu`/`storeu` 指令的在读写一个缓存行内时的1性能应该和 `load`/`store` 的性能相近。后者的优势在于，它们能作为免费的运行时断言，确保所有读写操作都处于对齐状态。（否则报错）

因此，在分配内存时正确对齐数组及其他数据至关重要，这也是编译器无法始终高效实现自动向量化的原因之一。在多数应用场景中，我们只需要确保任意 32 字节的 SIMD 数据块不会跨越缓存行边界。在 cpp 中，这可以通过 alignas 说明符来指定对齐方式：

```cpp
alignas(32) float a[n];

for (int i = 0; i < n; i += 8) {
    __m256 x = _mm256_load_ps(&a[i]);
    // ...
}
```

内置的向量类型本身已具备相应的对齐要求，并默认内存读写操作是对齐的——因此当你分配 `v8si` 类型的数组时总是安全的，但若要从 `int*` 指针转换为该类型，则必须确保源数据本身是对齐的。

与标量运算类似，许多向量算术指令可以直接将内存地址作为操作数——例如向量加法指令。不过开发者无法直接将其作为显式内联函数调用，而需依赖编译器优化实现。此外还存在其他特定的内存读取指令，尤其是非临时性加载/存储操作，这类指令能避免在缓存层级中保留所访问的数据。（可以查看上一章节）

### 寄存器别名

初代 SIMD 扩展指令集 MMX 的起点相当简单，仅支持 64 位向量运算。其设计巧妙地复用了 80 位浮点数尾数部分的存储空间，从而避免了引入独立的寄存器组。随着后续扩展逐步增大向量尺寸，为维持向后兼容性，向量寄存器沿用了通用寄存器采用的同名寄存器分层机制：例如 xmm0 对应 ymm0 的前半部分（128位），xmm1 对应 ymm1 的前半部分，依此类推。

这一特性，加上向量寄存器位于浮点处理单元的事实，使得在向量寄存器与通用寄存器之间传输数据的过程略显复杂。

### 提取和插入

要从向量中提取特定数值，可以使用 `_mm256_extract_epi32` 及类似的内联函数。该函数以需要提取的整数索引作为第二参数，并根据索引值的不同生成相应的指令序列。

当需要提取首元素时，编译器会生成 `vmovd` 指令（操作对象为向量的前半部分xmm0）：

```nasm
vmovd eax, xmm0
```

如果需要从 AVX 向量的后半部分提取任何元素，则必须先分离出该后半部分向量，再从中提取目标标量值。例如，以下是提取最后一个（第八个）元素的具体实现：

```nasm
vextracti128 xmm0, ymm0, 0x1
vpextrd      eax, xmm0, 3
```

有一个类似的 `_mm256_insert_epi32` 内部函数用于覆盖特定的元素：

```nasm
mov          eax, 42

; v = _mm256_insert_epi32(v, 42, 0);
vpinsrd xmm2, xmm0, eax, 0
vinserti128     ymm0, ymm0, xmm2, 0x0

; v = _mm256_insert_epi32(v, 42, 7);
vextracti128 xmm1, ymm0, 0x1
vpinsrd      xmm2, xmm1, eax, 3
vinserti128  ymm0, ymm0, xmm2, 0x1
```

总的来说，在标量数据与向量寄存器之间的数据传输效率较低，尤其当操作对象不是首元素时，性能损耗更为显著。

### 制造常量

如果你需要填充的不仅仅是一个元素，而是整个向量，你可以使用 `_mm256_setr_epi32` 内部函数：

```cpp
__m256 iota = _mm256_setr_epi32(0, 1, 2, 3, 4, 5, 6, 7);
```

此处 r 代表“反向”——这是从 CPU 视角而言的，对人类来说并不直观。另外还存在不带 r 的 `_mm256_set_epi32` 函数，其数据填充方向与之相反。这两种函数主要用于创建编译期常量，随后通过块加载指令将常量载入寄存器。若需将向量全部置零，应使用 `_mm256_setzero_si256` 函数：它通过让寄存器与自身进行异或运算实现归零。

对于内置的向量类型，直接使用常规花括号初始化即可：

```cpp
vec zero = {};
vec iota = {0, 1, 2, 3, 4, 5, 6, 7};
```

### 广播（Broadcast）

除了修改一个元素，你还可以将一个值广播到向量的所有位置：

```nasm
; __m256i v = _mm256_set1_epi32(42);
mov          eax, 42
vmovd        xmm0, eax
vpbroadcastd ymm0, xmm0
```

这是一个经常使用的操作，所以你也可以使用内存地址：

```nasm
; __m256 v = _mm256_broadcast_ss(&a[i]);
vbroadcastss ymm0, DWORD PTR [rdi]
```

在使用内部向量类型时，就可以使用零向量加上一个标量：

```cpp
vec v = 42 + vec{};
```

### 映射到数组

若希望规避上述所有复杂性，可以直接将向量数据转储至内存，再以标量形式读取其中的值。

```cpp
void print(__m256i v) {
    auto t = (unsigned*) &v;
    for (int i = 0; i < 8; i++)
        std::cout << std::bitset<32>(t[i]) << " ";
    std::cout << std::endl;
}
```

这种做法虽在执行效率或技术规范性上可能存在问题（C++ 标准未明确定义此类强制类型转换的行为），但其实现极为简洁。原作者在调试过程中就经常使用这段代码来输出向量内容。

### 不连续加载

后续的 SIMD 扩展指令集引入了特殊的“聚集”（gather）和“散射”（scatter）指令，能够通过任意数组索引实现非连续数据读写。虽然这些指令无法实现八倍速提升（通常受限于内存带宽而非 CPU 性能），但在稀疏线性代数等特定应用场景中仍极具价值。

聚集指令自 AVX2 架构开始支持，而各类散射指令则需 AVX512 架构才可实现。

![gather-scatter](/assets/simd/gather-scatter.png)

让我们测试一下它是否比标量读取更快一些。我们创建一个大小为 $N$ 的数组和 $Q$ 次随机查询：

```cpp
int a[N], q[Q];

for (int i = 0; i < N; i++)
    a[i] = rand();

for (int i = 0; i < Q; i++)
    q[i] = rand() % N;
```

在标量版本的代码中，我们将查询的指定元素逐个添加到校验和中：

```cpp
int s = 0;

for (int i = 0; i < Q; i++)
    s += a[q[i]];
```

在 SIMD 代码中，我们使用 gather 指令并行处理 8 个不同的索引：

```cpp
reg s = _mm256_setzero_si256();

for (int i = 0; i < Q; i += 8) {
    reg idx = _mm256_load_si256( (reg*) &q[i] );
    reg x = _mm256_i32gather_epi32(a, idx, 4);
    s = _mm256_add_epi32(s, x);
}
```

它们的性能大致相同，除了当数组大小可以放入 L1 缓存的时候：

![gather-scatter](/assets/simd/gather.svg)

> 可能是因为：在 L1 缓存上，一次提供多个地址读取比一个一个读取显然更快。而当缓存开销增加时，获取数据本身更加花费时间，时间瓶颈并不在到底是“一次提供多个地址”和“一个一个提供地址”上。
{: .prompt-warning }

`gather` 和 `scatter` 的设计目标并非加速内存操作，而是将数据高效载入寄存器以执行密集计算。对于计算成本超过单次加法操作的场景，这些指令都具有显著优势。

（高效）的聚集与散射指令的缺失，使得 CPU 上的 SIMD 编程模式与支持独立内存访问的真正并行计算环境截然不同（如 GPU）。开发者必须持续设计适配方案，通过多种数据重组策略将数据连续排列，才能将其有效载入寄存器。
