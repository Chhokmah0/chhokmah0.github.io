---
title: CUDA 概念笔记
date: 2026-1-31 2:00:00 +0800
categories: [笔记, GPU]
tags: [GPU, CUDA]     # TAG names should always be lowercase
math: true
---

## 大概念

异构计算：多个不同的计算设备构成的系统。

CPU：中央处理器。擅长执行串行代码，拥有分支预测、指令流水线、指令重排等功能。

GPU：图形处理器。擅长执行并行代码，拥有大量的计算单元，并以单指令多线程（SIMT）的方式运行。现在的 GPU 由于可编程能力的增加，所计算的范围已经远远超出了“图形”的概念。

动态随机存取存储器 (DRAM)：即内存。CPU 的 DRAM 被称为系统内存或主机内存，GPU 的 DRAM 被称为显存或全局内存（因为 GPU 的所有 SM 都可以访问 GPU 的 DRAM）。

统一内存 (Unified Memory)：CUDA 的一个特性叫做统一内存，它允许应用程序分配可以从 CPU 和 GPU 访问的内存。CUDA 运行时或底层硬件可以在需要时访问或重新定位数据到正确的位置（数据复制依然存在）。即使使用统一内存，通过保持内存迁移到最小并尽可能多地访问直接连接到内存所在的处理器的数据，也可以获得最佳性能。按需迁移也使得 GPU 的显存压力可以缓解（虚拟内存的感觉）。

主机 (Host)：一般指 CPU。

设备 (Device)：一般指 GPU。

核函数 (Kernel)：指在 GPU 上运行的函数。也被叫做设备代码，只是习惯于称呼为核函数。核函数启动时需要得知 Grid 和 Block 大小，同时还有一些可选的集群大小、流和 SM 配置设置。

SIMT：单指令多线程，多个线程同时执行一条指令来并行处理多组数据。

SIMD：单指令多数据，使用一条并行处理多组数据的指令。

## 硬件概念

图形处理集群 (Graphics Processing Clusters, GPCs)：GPC 中包含多个 SM。

流式多处理器 (Streaming Multiprocessors, SMs)：SM 中包含一个本地寄存器页（存储线程的局部变量）、一个同一数据缓存（L1 缓存 or 共享内存，存储一个 Block 的共享变量）、一个常量缓存 (Constant Cache)、大量 CUDA Core (计算单元，旧称 SP)。可以看到 CUDA Core 并不像 CPU Core 一样包含各种功能，其缓存、寄存器、调度功能都是由 SM 中别的硬软件同一管理。SM 是调度 Block 的基本单位。一个 SM 上能加载的 Block 数量取决于“SM 最大能调度的 Block 数量”、“SM 最大可运行的线程数量”、“SM 的共享内存限制”、“SM 的寄存器限制”，对于不同 GPU 的可能需要进行特殊对待才能充分利用 SM 的性能。

L2 cache：GPU 上的 cache，供给所有 SM 使用。

Warp Scheduler：SM 中调度 Warp 的调度单元，会将 Warp 在 32 个 CUDA Core 上进行调度，当一个 Warp 阻塞时会换一个 Warp。

PCIe or NVLINK：GPU 和 CPU 之间的总线，用于传输数据。

## 软件（模型）概念

Grid：包含多个 Block。启动一个核函数时就会生成一个 Grid，其中包含许多 Block，Block 中又包含许多线程。Grid 可以无限大，可以是 1、2、3 维。

Cluster：包含多个 Block。是 Grid 中 Block 的一个分组。也可以是多维的。Cluster 与 GPC 对应，从而使得 GPC 中的大量 Block 在 Grid 中是相邻的。由于这些 Block 同处于一个 GPC，因此同一个集群的不同块可以用  Cooperative Group 接口进行通讯。同一个集群的线程可以访问集群中任意 Block 的共享内存。集群的最大大小取决于硬件，与具体的设备有关。

Block：包含多个线程。Block 是 SM 的调度单位，一个 SM 可以同时调度多个（个位数大小）Block。Block 可以是 1、2、3 维。一个 SM 上能加载的 Block 数量取决于“SM 最大能调度的 Block 数量”、“SM 最大可运行的线程数量”、“SM 的共享内存限制”、“SM 的寄存器限制”，对于不同 GPU 的可能需要进行特殊对待才能充分利用 SM 的性能。由于 Block 内部的线程在同一个 SM 中运行，这允许这些线程共享 shared memory、进行同步 (`__syncthreads()`)。

Warp：包含 32 个线程，以单指令多线程的方式运行，相互之间自然是同步的。Block 中每 32 个线程组织成一个 Warp，这要求 Block 的大小最好是 32 的倍数。

## CUDA 平台概念

计算能力 (Compute Capability, CC)：每个 NVIDIA GPU 都有个 CC 编号，用于表示 GPU 支持哪些功能，以及设置一些硬件参数。CC 编号直接与 SM 的版本号对应，例如 CC 12.0 的 GPU 具有 `sm_120` 的 SM。

NVIDIA 驱动：可以被认为是GPU的操作系统，必须安装在主机系统的操作系统上。除了 CUDA 之外，NVIDIA Driver 还提供了使用 GPU 的所有其他方法，例如 Vulkan 和 Direct3D。

CUDA Toolkit：一组库、头文件、以及用于编写、构建、分析 CUDA 软件的工具。

CUDA 兼容性：GPU、NVIDIA 驱动、CUDA 工具集之间应该相互兼容。

CUDA API：CUDA 运行时 API 基于 CUDA 驱动 API 开发的。理论上，所有代码都可以使用 CUDA 驱动 API 来完成。有一些特性只能通过驱动 API 来利用。

```cpp
// Runtime API 示例代码 - 更简洁
cudaMalloc(&devPtr, size);
cudaMemcpy(devPtr, hostPtr, size, cudaMemcpyHostToDevice);
kernel<<<grid, block>>>(devPtr, N);
cudaDeviceSynchronize();

// Driver API 示例代码 - 更底层但更灵活
cuInit(0);
cuDeviceGet(&device, 0);
cuCtxCreate(&context, 0, device);
cuModuleLoad(&module, "kernel.ptx");
cuModuleGetFunction(&kernel, module, "myKernel");
cuLaunchKernel(kernel, ...);
```

Parallel Thread Execution (PTX)：CUDA 平台上平时基本不可见的层，PTX 是一个虚拟指令集，是 NVIDIA GPU 上的一个 high-level 的汇编语言。作为一个中间表示，这使得除了 nvcc 外，也可以使用其它编译器来编译 CUDA 程序的 PTX，然后通过 JIT 编译工具运行。PTX 版本也对应着计算能力，例如 `compute_80` 对应 CC 8.0。

Cubin：CUDA 二进制文件。对于特定的 SM 版本，cubin 有特殊的格式，例如 `sm_120`。

Fatbin：Fatbin 可以包含多个不同 SM 版本的 cubin 和多个不同 PTX 版本的 PTX。因此一个可执行程序或者库里面会包含 CPU 二进制代码和一个 fatbin。

二进制兼容性：在同一个大版本内（例如 8.x），CC 版本的 GPU 可以加载 SM 版本等于或小于 CC 版本的 cubin。不同大版本之间不能兼容。

PTX 兼容性：PTX 可以在运行时被 JIT 编译为 SM 版本等于或更高的 cubin。

JIT (just-in-time) 编译：运行时加载 PTX 代码会将其编译成二进制代码。JIT 会保存编码的程序以便后续使用。虽然牺牲了一些加载的耗时，但是 JIT 技术允许一个程序在当时并未出现的新设备上运行。

## 编程概念

线程束分化 (Warp Divergence)：由于一个 Warp 是以 SIMT 运行的，因此当 Warp 中的线程在某个条件分支中的判定不一致，就会使得 Warp 不得不将两个分支的指令都运行一遍。优化需要保证一个 Warp 中的线程尽可能执行相同的路径。

合并访存：当一个 Warp 的线程们访问全局内存中相邻的连续数据时，SM 可以只发出一次内存访问而非多次。优化需要保证一个 Warp 中的线程尽可能同时访问全局内存的相邻位置。
