---
title: 内存屏障笔记
date: 2025-2-11 2:00:00 +0800
categories: [笔记, 异步程序]
tags: [内存屏障, 多线程]     # TAG names should always be lowercase
math: true
---

刷 B 站偶遇 C++ 内存模型，偶遇内存屏障，拼尽全力无法战胜。

花了两天时间，看了五六篇博客以及 cpp 和 rust 的官方文档。目前看下来的结论是：内存屏障是跨越软件和硬件上的同步机制。在软件上，需要处理编译器的乱序执行（指令重排）所带来的问题；在硬件上，需要处理 CPU 的乱序执行和缓存一致性中 Store Buffer 与 Invalidate Queue 所带来的问题。或许可以将内存屏障看作是一系列的语义约定，程序员按照约定进行使用，而编译器、CPU 等则按照约定进行实现。

> 内存屏障并不影响原子变量的原子性，原子变量本身就会是同步的。内存屏障的主要目的在于保护其它非原子变量的可见性，例如在锁的释放时，保证所有线程能够看到在锁释放前发生的所有修改。
{: .prompt-tip}

## 乱序执行

为了加快运行速度，现代编译器和 CPU 都会进行乱序执行。编译器会删去部分死代码，调整运算顺序什么的。虽然运行结果和源代码一致，但是运行的过程却不一定一致，这就导致在多线程程序中，可能会发生一些预料之外的情况。

## 缓存一致性

除了乱序执行之外，现代 CPU 还有 cache，为了保证缓存一致性，比较常用的是 MEIS 方法。但是严格遵守 MEIS 又会带来性能上的损失，于是又引入了 Store Buffer 与 Invalidate Queue。Store Buffer 使得 CPU 可以直接修改值而不需要等待回复，等到回复后再将 Store Buffer 的内容写入 cache。Invalidate Queue 使得 CPU 可以直接回复 Ack，等到 CPU 空闲时再处理 Invalidate Queue 中的信息。

## 各种内存屏障

说是各种，其实主要还是记录一下 Rust 的内存屏障。它们和 C++20 的内存屏障是相同的，只是少了一些而已。

### Relaxed

语义：没有任何排序约束，只要求保证原子操作。

### Release

语义：当应用于存储操作时，对于所有以 `Acquire` 或更强的序加载此值的线程，保证 `Release` 之前的操作在存储操作发生之前执行。话句话说，存储操作之前的所有写操作都可以被以 `Acquire` 或更强的序加载此值的线程观测到。

此排序仅适用于可以执行存储的操作。如果将这个序用于既有加载又有存储的操作，那么加载是 `Relaxed` 的，而存储是 `Release` 的。

实现：软件上保证所有在 `Release` 之前的写操作不会被重排到 `Release` 之后，硬件上保证 `Release` 的存储操作之后需要将 Store Buffer 清空，刷入 cache，并等待其它所有线程返回 Invalidate Acknowledge 信息后才能继续运行。

### Acquire

语义：当应用于加载操作时，如果加载的值是以 `Release` 或更强的序被存储的，那么所有在 `Acquire` 之后发生的操作，保证在存储操作发生之后执行。话句话说，所有的后续的读操作都可以看到存储之前的写操作。

此排序仅适用于可以执行加载的操作。如果将这个序用于既有加载又有存储的操作，那么加载是 `Acquire` 的，而存储是 `Relaxed` 的。

实现：软件上保证所有在 `Acquire` 之后的读操作不会被重排到 `Acquire` 之前，硬件上保证 `Acquire` 的加载操作之前需要将 Invalidate Queue 清空。

### AcqRel

语义：同时具有 `Acquire` 和 `Release` 的效果：对于加载，它使用 `Acquire` 序。对于存储，它使用 `Release` 序。

注意，在 `compare_and_swap` 的情况下，有可能最终没有执行任何存储操作，此时它只有 `Acquire` 序。不过可以确定的是，`AcqRel` 永远不会执行 `Relaxed` 序。

### SeqCst (sequentially consistent)

语义：类似于 `Acquire` / `Release` / `AcqRel`（分别用于 `load`， `store` 和 `load-with-store` 操作），并额外保证所有的线程以相同的顺序看到所有 `SeqCst` 的操作。

猜测的实现：软件上不变，硬件上使用同步机制，保证总线只有一个 CPU 发 Invalidate 消息？总之主要的目的是让所有 CPU 核心中的 Store Buffer 和 Invalidate Queue 的顺序一致。

## 理论模型

上述的都是一些实现上的要求，但是对于代码编写的帮助仍然有限。这里总结一些理论上的东西，从而方便选择正确的内存序。

### 定义

***Sequenced-before (SB)***。在**同一线程**内，依据[语言标准](https://en.cppreference.com/w/cpp/language/eval_order.html)（如求值顺序、分号）确定的执行先后顺序。如果操作 A 在操作 B 之前发生，则称 A is sequenced-fecore B ($SB(A,B)$)。


***Modification Order (MO)***。所有线程对**单个原子对象**的所有修改（写/Read-Modify-Write (RMW)）形成一个全局一致的**全序**。所有线程都必须就这个顺序达成一致。大体上就是写操作有一个全序，同时读操作在已经观察到/推理出某个写操作发生的前提下，只能读取出这以及之后的写操作的值。

形式化的，MO 和 HB 产生了以下要求（对于 XY 一致性，有 A 操作是 X 操作，B 操作是 Y 操作。“之前/之后”不包括边界）：

1. 写写一致性：如果 $HB(A,B)$，则 $MO(A,B)$；
2. 读读一致性：如果 $HB(A,B)$，并且 A 读取的值来自于写操作 X 的可见副作用，那么 B 读取的值要么也是 X 的，要么就是在 MO 上出现在 X 之后的写操作 Y 的可见副作用；
3. 读写一致性：如果 $HB(A,B)$，那么 A 读取的值来自于在 MO 上出现在写操作 B 之前的写操作 X 的可见副作用。
4. 写读一致性：如果 $HB(A,B)$，那么 B 读取的值来自于写操作 A 的可见副作用，或者在 MO 上出现在 B 之后的写操作 X 的可见副作用；

***Synchronizes-with (SW)***。相当于线程之间的一种协议，$SW(A,B)$ 使得线程 1 中的操作 A 之前的操作对线程 2 的操作 B 都是可见且有序的。该关系在运行时确定。

***Inter-thread Happens-before (ITHB)***。（c++26 后已经不再使用 ITHB 这个概念了，可以无视）在线程之间，如果以下任意条件为真，则 $ITHB(A,B)$：

- $SW(A,B)$；
- $SW(A,X)$ 且 $SB(X,B)$；
- $SB(A,X)$ 且 $ITHB(X,B)$；
- $ITHB(A,X)$ 且 $ITHB(X,B)$。

***Happens-before (HB)***。如果以下任意条件为真，则 $HB(A,B)$：

- $SB(A,B)$；
- $SW(A,B)$；
- $HB(A,X), HB(X,B)$。

ITHB 是 HB 的一个子集，它只关注跨线程的那一部分。HB 本身则被用于定义副作用的可见性。

***Strongly Happens-before (SHB)***。如果以下任意条件为真，则 $SHB(A,B)$：

- $SB(A,B)$；
- $SW(A,B)$，且 A 和 B 都是 SeqCst 原子操作；
- $SB(A,X), HB(X,Y)$，且 $SB(Y,B)$；
- $SHB(A,X), SHB(X,B)$。

其中第二和第三种情况统一起来，相当于从 HB 关系中排除掉了非 SeqCst 的 $SW(X,Y)$ 产生的 HB 关系。

如果 $SHB(A,B)$，在 SeqCst 模型中，在任何上下文关系中，SeqCst 操作 A 都在 SeqCst 操作 B 之前。

***可见副作用***。对于标量 M，一个有副作用的操作 A 对 B 可见，**当且仅当** $HB(A,B)$ 且 A 和 B 在 HB 关系上之间没有其他有副作用的操作 X。($VIS(A,B)$，这里 A 必须是写操作，B 必须是读操作)

如果两个之间没有 HB 关系的标量操作 A 和 B 对同一个内存地址进行操作，且其中至少一个是写操作，那么这两个操作就会产生数据竞争。

***Acquire 操作***。所有使用 Acquire 或更强内存顺序的原子加载是 Acquire 操作。Mutex 上的 `lock()` 操作也是获取操作。请注意，`std::atomic_thread_fence` 施加了比 Acquire 操作更强的同步要求。

***Release 操作***。所有使用 Release 或更强内存顺序的原子加载是 Release 操作。Mutex 上的 `unlock()` 操作也是获取操作。请注意，`std::atomic_thread_fence` 施加了比 Release 操作更强的同步要求。

而内存序的作用就是确定哪些操作之间会产生 SW 关系。值得注意的是，不是所有的操作之间都有 HB 关系，也就是说 HB 是一个偏序而非全序。

线程间的同步就可归结为两点：通过建立 HB 关系来防止数据竞争，以及明确在何种条件下哪些副作用会变得可见。

形式化的，验证流程为：

1. 提取代码的 SB 关系。
2. 枚举并验证 MO 关系。此时 MO 中的每个原子变量的写操作至少应该满足 SB 关系的顺序。（约等于剪枝，验证的步骤其实可以最后再做）
3. 枚举并验证 SW 关系。将原子操作的 Acq 和 Rel 进行配对，并验证是否满足之前枚举出的 SB 和 MO 关系。
4. 计算 HB 关系。
5. 验证一致性。包括数据竞争检查和内存一致性检查（MO 中的读读、读写那一套）。
6. 对于所有通过的执行路径，检查是否满足要求。

### Sequentially Consistent (SeqCst) 模型

SC 模型假定了：

- 所有的 SC 操作（使用了 SeqCst 序的原子操作或者屏障）之间都有个顺序（即在上面有一个 SW 的全序），与观测的线程无关。
- 对于同一原子变量的操作 A 和 B，若 B 读取了 A 操作写入的值 $(VIS(A,B))$，则 $SW(A,B)$。也就是说 SC 操作至少同时具有 Acquire 和 Release 的效果。

我们定义一个新东西：

***coherence-ordered-before (COB)***。对于一个原子变量 M 的两个操作 A 和 B，$COB_M(A,B)$ 当以下任意条件为真：

- （写读）$VIS(A,B)$；
- （写写）$MO_M(A,B)$；
- （读写）$VIS(X,A)$，且 $MO_M(X,B)$，同时 A 和 B 不是同一个 RMW 操作；
- $COB_M(A,X),COB_M(X,B)$。

那么***所有的 SC 操作（包含屏障）的一个单一总序 $S$*** 需要满足：

- 若 $SHB(A,B)$，则 $S(A,B)$。
- 对于任意 M 上的满足 $COB_M(A,B)$ 的两个 SeqCst，需要满足：
  1. 若 A 和 B 都是 SeqCst 操作，那么 $S(A,B)$；
  2. 若 A 是 SeqCst 操作，对于 SeqCst 屏障 Y，若 $HB(B,Y)$，则 $S(A,Y)$；
  3. 对于屏障 SeqCst X，若 $HB(X,A)$，且 B 是 SeqCst 操作，则 $S(X,B)$；
  4. 对于屏障 SeqCst X,Y，若 $HB(X,A),HB(B,Y)$，则 $S(X,Y)$。

考虑如下案例：

```cpp
std::atomic<bool> x{false}, y{false};
std::atomic<int> z{0};

void write_x() { x.store(true); } // A
void write_y() { y.store(true); } // B
void read_x_then_y()
{
    while (!x.load()); // C
    if (y.load())      // D
        ++z;
}
void read_y_then_x()
{
    while (!y.load()); // E
    if (x.load())      // F
        ++z;
}
```

可以直接得出的顺序有 $SB(C,D),SB(E,F)$，推出 $SHB(C,D),SHB(E,F)$。同时 C 和 E 的循环迭代保证了对应的原子变量一定要存入 `true` 后才往下一步走，因此有 $SW(A,C),SW(B,E)$。由于所有的操作都是 SeqCst 操作，最终推出 SHB 至少有 $SHB(A,C,D),SHB(B,E,F)$。

虽然所有的 SC 操作保证有一个全序 $S$，但是却不保证全序具体是什么，因此接下来需要分类讨论：

- 如果 $S(A,B)$，则有 $S(A,C,D)$ 和 $S(A,B,E,F)$ 两条链条，其中第二个链条使得 F 的条件一定成立，因此执行了 `++z`。但所有的 SC 操作必须是一个全序，因此还需要额外的分类讨论。虽然两条链的合并方式有很多种，不过其中重要的只有两种情况：
  - 若 $S(B,D)$，则 D 的条件一定成立，执行了 `++z`；
  - 若 $S(D,B)$，则 D 的条件一定不成立；
- 如果 $S(B,A)$，同理。

因此我们得到结论，四个线程同时运行结束后，`z==1` 或 `z==2`。

### Acquire-Release (AcqRel) 模型

- 只有读操作可以是 Acquire 的，只有写操作可以是 Release 的；
- 对于同一变量的 Release 操作 A 和 Acquire 操作 B，若 B 读取到了 A 写入的值，则 $SW(A,B)$；
- 同步仅在**释放**和**获取**相同原子变量的线程之间建立。其他线程可能看到与一个或两个同步线程不同的内存访问顺序。

考虑如下案例：

```cpp
std::atomic<std::string*> ptr{ nullptr };
int data = 0;

// Thread 1
void producer()
{
    std::string* p = new std::string("Hello"); // A
    data = 42;                                 // B
    ptr.store(p, std::memory_order_release);   // C
}

// Thread 2
void consumer()
{
    std::string* p2;
    while (!(p2 = ptr.load(std::memory_order_acquire))); // D
    assert(*p2 == "Hello"); // E
    assert(data == 42);     // F
}
```

由于 $SW(C,D)$ 给出了 $HB(C,D)$，因此可以通过 HB 的传递性得到 $HB(A,E)$ 和 $HB(B,F)$，从而 E 和 F 一定能看到 A 和 B 带来的可见副作用，两个 `assert` 一定正确。

那么什么时候必须使用 SeqCst？考虑之前 SC 模型的案例，将其修改为 AcqRel 序：

```cpp
std::atomic<bool> x{false}, y{false};
std::atomic<int> z{0};

void write_x() { x.store(true, std::memory_order_release); } // A
void write_y() { y.store(true, std::memory_order_release); } // B
void read_x_then_y()
{
    while (!x.load(std::memory_order_acquire)); // C
    if (y.load(std::memory_order_acquire))      // D
        ++z;
}
void read_y_then_x()
{
    while (!y.load(std::memory_order_acquire)); // E
    if (x.load(std::memory_order_acquire))      // F
        ++z;
}
```

在 SC 模型中，$S(A,B)$ 或者 $S(B,A)$ 是由模型强行规定必须选其一的，而现在这没有这个要求了。因此这里只存在链 $HB(A,C,D)$ 和 $HB(B,E,F)$。A 的副作用对 F 不一定可见，B 的副作用对 D 也不一定可见。没有 HB 关系阻止 $MO_x(F,A,C)$ 和 $MO_y(D,B,E)$ 的 MO。（虽然 MO 本质只考虑修改序，而这里的修改操作只有 A 和 B，但是其它线程的读操作不会影响到本线程，因此只需要从 $MO_x$ 中剔除其它线程的读操作就可以得到本线程认为自己的读操作发生在哪个写操作之后，这样的写法应该还算合理。）

实际上，在线程 `read_x_then_y` 看到 $(A,C,D,B)$，线程 `read_y_then_x` 看到 $(B,E,F,A)$ 时，就会产生 `z==0`。即不同线程认为 A 和 B 的顺序不一样。

### Relaxed 模型

不产生任何 SW 关系，只保证原子性和 MO。

先考虑一个 AcqRel 的例子：

```cpp
std::atomic<int> x{0}, y{0};

void read_y_then_write_x(int& r1)
{
    r1 = y.load(std::memory_order_acquire); // A
    x.store(r1, std::memory_order_release); // B
}

void read_x_then_write_y(int& r2)
{
    r2 = x.load(std::memory_order_acquire); // C
    y.store(42, std::memory_order_release); // D，注意这里写入的是常数
}

int main()
{
    int r1 = 0, r2 = 0;
    std::jthread{ read_y_then_write_x, std::ref(r1) }, 
                { read_x_then_write_y, std::ref(r2) };
    assert(!(r1 == 42 && r2 == 42));
}
```

可以推出链条 $SB(A,B),SB(C,D)$。

虽然可以正着分类讨论，但我们也可以用反证法。

假设最终 `r1 == 42 && r2 == 42` 成立。`r1 == 42` 说明 A 拿到了 D 写入的值，由于 Rel 和 Acq 序，建立了 $SW(D,A)$ 关系。同时 `r2!=0` 也建立了 $SW(B,C)$ 关系。这导致在 HB 关系图上出现了一个环。根据读写一致性 $HB(A,D)$ 和写读一致性 $HB(D,A)$，A 既要读取到 D 之前的 0，又要拿到 D 及之后的 42，这是不可能的（在 MO 上既要 $<$ 又要 $\geq$）。因此有 `!(r1 == 42 && r2 == 42)`。

正着推的话也可以得到其它三种情况都有可能出现。

现在考虑 Relaxed 序下的案例：

```cpp
std::atomic<int> x{0}, y{0};

// Thread 1:
r1 = y.load(std::memory_order_relaxed); // A
x.store(r1, std::memory_order_relaxed); // B
// Thread 2:
r2 = x.load(std::memory_order_relaxed); // C 
y.store(42, std::memory_order_relaxed); // D
```

尽管 $SB(A,B),SB(C,D)$，但是没有任何东西阻止 $MO_y(D,A)$ 和 $MO_x(B,C)$ 的修改顺序同时存在。在实际中，这是因为编译器或者运行时重排了 C 和 D。

宽松内存排序的一个典型用途是增加计数器，例如 `std::shared_ptr` 的引用计数器，因为这只需要原子性，而不需要排序或同步（但要注意 `std::shared_ptr` 计数器需要与析构函数进行获取-释放同步）。

## 参考文献

[1] [cpprefence](https://en.cppreference.com/w/cpp/atomic/memory_order)  
[2] [rust std](https://doc.rust-lang.org/std/sync/atomic/enum.Ordering.html)  
[3] [说透缓存一致性与内存屏障](https://www.cnblogs.com/chanmufeng/p/16523365.html)  
[4] [不是你怎么变来变去的：详解 C++ Memory Order 理论模型](https://zhuanlan.zhihu.com/p/1911798716026826993)
