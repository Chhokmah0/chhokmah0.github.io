---
title: 高性能计算-第五章-分析
date: 2025-2-09 12:00:00 +0800
categories: [笔记，高性能计算]
tags: [hpc]     # TAG names should always be lowercase
math: true
---
## 序 - 分析

在寻找性能问题时，盯着源代码和汇编代码是最常用的方式，但它并不是最有效的方式。当性能和预期不符时，我们可以使用一种被称为 _性能分析工具（profilers）_ 的特殊程序来更快地找到根本原因。

性能分析工具有许多不同的类型。原作者喜欢将它们类比为物理学家或者其他自然科学家研究微小物体时，会根据所需要的精度选择合适的工具。

有三种主要的性能分析技术，它们各自都有其独特的原理、适用范围、精度：

1. _插桩分析（Instrumentation）_：允许我们计时整个或部分程序，并统计我们感兴趣的事件。
2. _统计性能分析（Statistical Profiling）_：允许我们深入到汇编级别，跟踪各种硬件事件。比如分支预测失败或者缓存未命中，这些对性能至关重要。
3. _程序模拟（Program Simulation）_：允许我们深入到单个时钟周期的级别，查看 CPU 在执行一小段汇编代码时，每个周期内所发生的情况。

实际的算法设计也可以被看作是一个经验领域。我们很大程度上依赖于相同的实验方法。这并不是因为我们不了解自然的一些基本秘密，而是因为现代计算机过于复杂，难以分析。此外，作为普通的软件工程师，由于硬件公司的知识产权保护，我们也无法了解某些细节（事实上，考虑到最准确的 x86 指令表是通过逆向工程获得的，有理由相信英特尔自己也不完全了解这些细节）。

在本章中，我们将研究这三种关键的性能分析方法，以及一些通过时间检验的如何设计进行性能评估的计算实验的实践方法。

## 一 - 插桩分析

插桩是一个有点复杂的术语，它表示在程序中插入计时器或其他跟踪代码。最简单的例子是在类 Unix 系统中使用 `time` 程序来衡量整个程序的运行时间。

一般情况下，我们想要知道程序的哪些部分需要优化。编译器和 IDE 通常会附带一些工具，可以自动计时指定的函数，但更健壮的方式是手动使用编程语言提供的计时方式来实现：

```cpp
clock_t start = clock();
do_something();
float seconds = float(clock() - start) / CLOCKS_PER_SEC;

printf("do_something() took %.4f", seconds);
```

```rust
use std::time::{Duration, Instant};
let start = Instant::now();
expensive_function();
let duration = start.elapsed();

println!("Time elapsed in expensive_function() is: {:?}", duration);
```

这里的一个细微差别是，您无法通过这种方式测量特别快速的函数的执行时间，因为 clock 函数返回的时间戳精度是微秒（$10^{-6}$ 秒）（Rust 的精度依赖于操作系统和硬件），而且它本身也需要几百纳秒才能完成。所有其他与时间相关的工具也同样至少具有微秒级别的精度，这在底层优化领域已经算是很长的时间了。

为了实现更高的精度，我们可以在循环中重复调用该函数，计时整个循环，然后将总时间除以迭代次数。

我们还需要确保没有任何内容被缓存，没有任何内容被编译器优化，也没有任何内容受到副作用的影响。这是一个独立且非常复杂的话题，我们将在本章的末尾详细讨论。

### 事件采样

插桩还可以用来收集其他类型的信息，这些信息可以为特定算法的性能提供有用的观察，例如：

- 对于哈希函数，我们关心其输入的平均长度。
- 对于二叉树，我们关心其高度和大小。
- 对于排序算法，我们希望知道它进行了多少次比较。

用类似的方式，我们可以在代码中插入计数器来计算这些和算法相关的统计数据。

添加计数器的缺点是会引入开销，不过我们可以随机计数一小部分调用来几乎缓解这一问题：

```cpp
void query() {
    if (rand() % 100 == 0) {
        // update statistics
    }
    // main logic
}
```

如果采样率足够小，每次调用的额外的开销就只是随机数生成和条件检查。有趣的是，我们可以通过一些统计学的技巧进一步优化它。

从数学上讲，我们在这里所做的是从 _伯努利分布（Bernoulli distribution）_（以 $p$ 作为采样率）中重复采样，直到获得成功。还有一种分布可以告诉我们，在第一次成功之前需要进行多少次伯努利采样，这种分布称为 _几何分布（geometric distribution）_。我们可以从中采样，并将该值用作递减计数器：

```cpp
void query() {
    static next_sample = geometric_distribution(sample_rate);
    if (next_sample--) {
        next_sample = geometric_distribution(sample_rate);
        // ...
    }
    // ...
}
```

这样我们就不需要在每次调用时生成一个新的随机数，并且只有在计算统计信息时才重置计数器。

大型项目中的库算法开发人员经常使用这样的技术来收集分析数据，它们不会对最终程序的性能造成太大影响。

## 二 - 统计性能分析

在性能分析的时候，插桩是一种无聊的工作，特别是当我们对程序的多个小部分感兴趣时。尽管插桩可以通过工具部分地自动化，但由于其本身固有的开销，它仍然无法收集一些细粒度的统计信息。

另一种侵入性较小的性能分析方法是：以随机的时间间隔中断程序的执行，并查看指令指针的位置。指针在每个函数块中停止的次数大致与执行这些函数所花费的总时间成正比。通过这种方式，我们还可以获得其他一些有用的信息，例如检查调用堆栈来找出哪些函数调用了哪些函数。

原则上，这可以通过使用 `gdb` 运行程序并在随机时间间隔按下 `ctrl+c` 来实现，但现代 CPU 和操作系统为这种性能分析提供了专门的工具。

### 硬件事件

_硬件性能计数器（Hardware Performance Counters）_ 是微处理器中内置的特殊寄存器，可以存储某些和硬件活动相关的计数。它们在芯片上的实现成本很低，因为它们基本上只是二进制计数器，将一根激活线连接到它们就好。

每个性能计数器都连接到大部分电路，并且可以配置为在特定硬件事件（例如分支预测失败或缓存未命中）发生时递增。我们可以在程序开始时重置计数器，运行程序，然后在结束时输出其存储的值，这样的值就等于整个执行过程中触发特定事件的次数。

我们还可以通过在多个事件之间进行多路复用来跟踪多个事件，即以固定间隔停止程序并重新配置计数器。在这种情况下，结果将不是精确的，而是一个统计的近似值。和插桩分析的区别在于，这里的准确性不能通过简单地增加采样频率来提高，因为这会严重影响性能，从而改变分布。因此如果我们要收集多个统计数据，就需要将程序运行更长的时间。

总的来说，基于事件的统计性能分析通常是诊断性能问题最简单有效的方法。

### 使用 perf 进行性能分析

依赖于上述事件采样技术的性能分析工具称为 _统计性能分析器（statistical profiler）_。这类工具有很多，但我们在本书中主要使用的是 perf，它是 Linux 内核附带的一个统计性能分析器。在非 Linux 系统上，可以使用英特尔的 VTune，它提供了与我们目标大致相同的功能。VTune 是免费的，但它是专有软件，您需要每 90 天刷新一次社区许可证，而 perf 则是完全自由的。

Perf 是一个命令行应用程序，它基于程序的实时运行生成报告。Perf 不需要源代码，并且可以分析非常多种类的应用程序，甚至包括涉及多个进程和与操作系统进行交互的程序。

下面的程序创建了一个包含一百万个随机整数的数组，对其排序、然后执行了一百万次的二分查找：

```rust
use rand::{
    distr::{Distribution, Uniform},
    SeedableRng,
};
const N: usize = 1_000_000;

pub fn statistical_profiling_init() -> Vec<usize> {
    let mut rng = rand::rngs::StdRng::seed_from_u64(0);
    let uniform = Uniform::new(0, usize::MAX).unwrap();
    let mut vec: Vec<usize> = uniform.sample_iter(&mut rng).take(N).collect();
    vec.sort_unstable();
    vec
}

pub fn statistical_profiling_query() -> usize {
    let mut rng = rand::rngs::StdRng::seed_from_u64(10);
    let uniform = Uniform::new(0, usize::MAX).unwrap();
    let vec = statistical_profiling_init();
    let mut check_sum = 0;
    for _ in 0..N {
        let r = uniform.sample(&mut rng);
        let p = vec.partition_point(|x| *x < r);
        check_sum += p;
    }
    check_sum
}
```

使用 `cargo build --release` 编译后，我们可以使用 `perf stat ./exe` 运行程序，它会输出运行过程中的一些基本计数信息（WSL 不支持部分计数器，而且还是些很重要的计数器）：

```text
 Performance counter stats for './target/release/statistical_profiling':

             83.18 msec task-clock:u                     #    0.841 CPUs utilized
                 0      context-switches:u               #    0.000 /sec
                 0      cpu-migrations:u                 #    0.000 /sec
               491      page-faults:u                    #    5.903 K/sec
   <not supported>      cycles:u
   <not supported>      instructions:u
   <not supported>      branches:u
   <not supported>      branch-misses:u

       0.098864220 seconds time elapsed

       0.083613000 seconds user
       0.000000000 seconds sys
```

我们可以使用 `perf list` 获得所有支持事件的列表，然后使用 `-e` 选项指定想要的特定事件列表。例如，对于诊断二分查找，我们主要关心缓存丢失（WSL 不支持）：

```text
 Performance counter stats for './target/release/statistical_profiling':

   <not supported>      cache-references:u
   <not supported>      cache-misses:u

       0.092380863 seconds time elapsed

       0.084872000 seconds user
       0.000000000 seconds sys
```

要尝试我们之前讨论的停止世界方法，我们需要使用 `perf record <cmd>`，它会记录性能分析数据并将其转储为 `perf.data` 文件，然后调用 `perf report` 来展示它。原作者强烈建议自己去尝试一下，因为最后一个命令是交互式的并且有丰富的颜色显示，但对于那些现在无法尝试的人，我会尽力描述它。

```text
Samples: 282  of event 'task-clock:upppH', Event count (approx.): 70500000
Overhead  Command          Shared Object          Symbol
  68.44%  statistical_pro  statistical_profiling  [.] hpc_rs::profiling::statistical_profiling::statistical_profiling_query
  23.40%  statistical_pro  statistical_profiling  [.] core::slice::sort::unstable::quicksort::quicksort
   2.48%  statistical_pro  statistical_profiling  [.] rand_chacha::guts::refill_wide::impl_avx2
   2.13%  statistical_pro  statistical_profiling  [.] core::slice::sort::shared::smallsort::small_sort_network
   2.13%  statistical_pro  statistical_profiling  [.] hpc_rs::profiling::statistical_profiling::statistical_profiling_init
   0.35%  statistical_pro  ld-linux-x86-64.so.2   [.] _dl_lookup_symbol_x
   0.35%  statistical_pro  ld-linux-x86-64.so.2   [.] get_common_cache_info.constprop.0
   0.35%  statistical_pro  libc.so.6              [.] __memmove_avx_unaligned_erms
   0.35%  statistical_pro  statistical_profiling  [.] _ZN4core5slice4sort6shared5pivot11median3_rec17h5b086f6d98fcc7c1E.llvm.15275026995077054455
```

注意到对于每个函数，它只列出了其自己的开销而不是总的运行时间（例如，`init` 函数中有 `sort`，但是在统计中会发现 `init` 的开销占比更少）。有一些工具可以从报告中生成火焰图，可以更清楚地查看结果。例外，我们还应该考虑可能发生的函数内联，例如我们调用的是 `sort_unstable()`，但是最终的分析中却只有 `quicksort()`。Perf 同样可以跟踪共享库（例如 `libc`）或者其它生成的线程：如果你想的话，可以用 perf 跟踪一个 web 浏览器，看看会发生什么。

接下来，我们可以“放大”其中任何一个函数，它会显示其反汇编的代码以及相关的热图。例如，以下是 `query` 的放大：

```text
query  /mnt/d/code/rust/hpc/target/release/statistical_profiling [Percent: local period]
Percent│       test   %r13,%r13
       │     ↑ je     1da
       │2a6:   cmp    $0x1,%r13
       │     ↑ je     1d0
       │       mov    %r13,%rsi
       │       xor    %edx,%edx
       │       data16 cs nopw 0x0(%rax,%rax,1)
  0.52 │2c0:   mov    %rsi,%rdi
  1.04 │       shr    $1,%rdi
  1.55 │       lea    (%rdi,%rdx,1),%r8
  4.66 │       cmp    (%r14,%r8,8),%rcx
 86.01 │       cmova  %r8,%rdx
  5.18 │       sub    %rdi,%rsi
       │       cmp    $0x1,%rsi
       │     ↑ ja     2c0
       │     ↑ jmp    1d2
       │2e0:   mov    0x18(%rsp),%rsi
       │       test   %rsi,%rsi
```

最左列是 _指令指针（instruction pointer, IP）_ 停留在这一行的次数。你可以看到我们花费了 ~86% 的事件在 `cmova` 指令上，而它的前一条指令是 `cmp`，说明 `cmova` 在等待 `cmp` 执行完毕后的结果。

由于流水线和乱序执行等技术的复杂性，在现代 CPU 中，“现在”这个概念并不是良定义的。因此数据会有一些不准确，因为指令指针会稍微向前偏移一点。尽管指令级别的统计数据仍然有用，但到了单个周期的级别上，我们需要切换到更精确的工具。

### 程序模拟

性能分析的最后一种方法（或者说方法集合）不是通过实际运行程序来收集数据，而是通过使用专门工具进行模拟来分析预期会发生的情况。

这类剖析工具有许多子类别，差异在于它们模拟的是计算的哪些方面。在本文中，我们将重点关注缓存和分支预测，并使用 Cachegrind 来实现这一点，它是Valgrind 中面向分析的部分，Valgrind 是一个完善的内存泄漏检测和内存调试工具。

### 使用 Cachegrind 进行分析

Cachegrind 通过对二进制文件中的“关键”指令（内存读/写，条件/间接跳转）插桩，用软件数据结构模拟相应的硬件操作。因此它无需源代码就可以直接分析已经编译的程序，可以通过以下命令执行：

```bash
valgrind --tool=cachegrind --cache-sim=yes --branch-sim=yes ./run
```

`--cache-sim=yes` 开启了缓存命中模拟，而 `--branch-sim=yes` 开启了分支预测模拟。

该工具会对所有相关二进制文件进行插桩，运行后会生成与 `perf stat` 类似的摘要信息：

```text
==4225== 
==4225== I refs:        413,781,398
==4225== I1  misses:          1,800
==4225== LLi misses:          1,759
==4225== I1  miss rate:        0.00%
==4225== LLi miss rate:        0.00%
==4225== 
==4225== D refs:        109,200,557  (66,688,157 rd   + 42,512,400 wr)
==4225== D1  misses:     11,090,998  (10,962,336 rd   +    128,662 wr)
==4225== LLd misses:        127,365  (     1,740 rd   +    125,625 wr)
==4225== D1  miss rate:        10.2% (      16.4%     +        0.3%  )
==4225== LLd miss rate:         0.1% (       0.0%     +        0.3%  )
==4225== 
==4225== LL refs:        11,092,798  (10,964,136 rd   +    128,662 wr)
==4225== LL misses:         129,124  (     3,499 rd   +    125,625 wr)
==4225== LL miss rate:          0.0% (       0.0%     +        0.3%  )
==4225== 
==4225== Branches:       39,150,582  (39,058,041 cond +     92,541 ind)
==4225== Mispredicts:     1,600,264  ( 1,599,945 cond +        319 ind)
==4225== Mispred rate:          4.1% (       4.1%     +        0.3%   )
```

Cachegrind 显示的数据与 perf 大致相同，只是 perf 测量的内存读取和分支数量由于预测执行而略微膨胀：在实际的硬件上会有分支预测执行，因此增加了硬件计数器，而这些在模拟中却会被忽略。

Cachegrind 仅模拟第一级（数据 D1，指令 I1）和末级（LL）缓存，参数根据系统自动推断。也可通过命令行自定义，例如使用 `--LL=<size>,<associativity>,<line size>` 参数指定 L2 缓存的特征。

现在来看，cachegrind 似乎只是让我们的程序变慢了，而没有什么 `perf stat` 不能提供的信息。为了获取更多的信息，我们可以查看一个带有信息的特殊文件，默认情况下它会将其存储到名为 `cachegrind.out.<pid>` 的文件中。它是人类可读的，但将通过 `cg_annotate` 命令读取更好：

```bash
cg_annotate cachegrind.out.4225 --show=Dr,D1mr,DLmr,Bc,Bcm
```

首先它显示了我们运行的参数，其中包括缓存系统的特征：

```text
I1 cache:         32768 B, 64 B, 8-way associative
D1 cache:         49152 B, 64 B, 12-way associative
LL cache:         25165824 B, 64 B, 12-way associative
```

接下来，它输出类似于 `perf report` 的每个函数汇总信息：

```text
--------------------------------------------------------------------------------
-- File:function summary
--------------------------------------------------------------------------------
  Dr_______________________ D1mr_______________________ DLmr___________ Bc_______________________ Bcm_____________________  file:function

< 66,319,999 (99.4%, 99.4%) 10,960,013 (100.0%, 100.0%) 13 (0.7%, 0.7%) 38,855,782 (99.5%, 99.5%) 1,594,763 (99.7%, 99.7%)  ???:
  22,000,025 (33.0%)         9,471,620  (86.4%)          0              24,031,251 (61.5%)        1,031,286 (64.5%)           hpc_rs::profiling::statistical_profiling::statistical_profiling_query
  32,735,752 (49.1%)         1,461,648  (13.3%)          0               8,461,529 (21.7%)          154,159  (9.6%)           core::slice::sort::unstable::quicksort::quicksort
     625,000  (0.9%)             1,350   (0.0%)          2 (0.1%)          437,500  (1.1%)               14  (0.0%)           rand_chacha::guts::refill_wide::impl_avx2
   4,213,883  (6.3%)               125   (0.0%)          0               2,632,002  (6.7%)          371,302 (23.2%)           core::slice::sort::shared::smallsort::small_sort_network
   5,000,033  (7.5%)                 4   (0.0%)          0               3,031,253  (7.8%)           31,263  (2.0%)           hpc_rs::profiling::statistical_profiling::statistical_profiling_init
   1,369,600  (2.1%)            24,812   (0.2%)          0                 136,960  (0.4%)            6,636  (0.4%)           core::slice::sort::shared::pivot::median3_rec
     375,000  (0.6%)               397   (0.0%)          0                 125,000  (0.3%)                1  (0.0%)           rand_chacha::guts::refill_wide

<    291,894  (0.4%, 99.9%)        133   (0.0%, 100.0%)  3 (0.2%, 0.9%)    146,039  (0.4%, 99.9%)        67  (0.0%, 99.7%)  ./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S:
     291,796  (0.4%)               129   (0.0%)          1 (0.1%)          145,960  (0.4%)               31  (0.0%)           __memcpy_avx_unaligned_erms

--------------------------------------------------------------------------------
-- Function:file summary
--------------------------------------------------------------------------------
  Dr_______________________ D1mr_____________________ DLmr__________ Bc_______________________ Bcm_____________________  function:file

> 22,000,025 (33.0%, 33.0%) 9,471,620 (86.4%,  86.4%) 0 (0.0%, 0.0%) 24,031,251 (61.5%, 61.5%) 1,031,286 (64.5%, 64.5%)  hpc_rs::profiling::statistical_profiling::statistical_profiling_query:???
> 32,735,752 (49.1%, 82.1%) 1,461,648 (13.3%,  99.7%) 0 (0.0%, 0.0%)  8,461,529 (21.7%, 83.2%)   154,159  (9.6%, 74.1%)  core::slice::sort::unstable::quicksort::quicksort:???
>    625,000  (0.9%, 83.0%)     1,350  (0.0%,  99.7%) 2 (0.1%, 0.1%)    437,500  (1.1%, 84.3%)        14  (0.0%, 74.1%)  rand_chacha::guts::refill_wide::impl_avx2:???
>  4,213,883  (6.3%, 89.3%)       125  (0.0%,  99.7%) 0 (0.0%, 0.1%)  2,632,002  (6.7%, 91.0%)   371,302 (23.2%, 97.3%)  core::slice::sort::shared::smallsort::small_sort_network:???
>  5,000,033  (7.5%, 96.8%)         4  (0.0%,  99.7%) 0 (0.0%, 0.1%)  3,031,253  (7.8%, 98.8%)    31,263  (2.0%, 99.3%)  hpc_rs::profiling::statistical_profiling::statistical_profiling_init:???
>  1,369,600  (2.1%, 98.9%)    24,812  (0.2%, 100.0%) 0 (0.0%, 0.1%)    136,960  (0.4%, 99.2%)     6,636  (0.4%, 99.7%)  core::slice::sort::shared::pivot::median3_rec:???
>    375,000  (0.6%, 99.4%)       397  (0.0%, 100.0%) 0 (0.0%, 0.1%)    125,000  (0.3%, 99.5%)         1  (0.0%, 99.7%)  rand_chacha::guts::refill_wide:???
>    291,796  (0.4%, 99.9%)       129  (0.0%, 100.0%) 1 (0.1%, 0.2%)    145,960  (0.4%, 99.9%)        31  (0.0%, 99.7%)  __memcpy_avx_unaligned_erms:./string/../sysdeps/x86_64/multiarch/memmove-vec-unaligned-erms.S
```

你可以看到，在排序阶段有很多分支预测错误（Bcm），在二分搜索过程中也有很多 L1 缓存丢失（D1mr）和分支预测错误。我们不能通过 `pref` 得到这些信息——它只能告诉我们整个程序的这些计数。

Cachegrind的另一个重要特性是对源代码的逐行注释。为此，我们需要带着调试信息（GCC 为添加 -g，Rust 在 cargo.toml 中对 profile 添加 debug=2）编译程序，并显式地告诉 `cg_annotate` 要注释哪些源文件，或者只是传递一个 `——auto=yes` 选项，让它自动注释它可以到达的所有文件（包括标准库源代码）。

```rust
        .           .    .          .                 .              /// ```
        .           .    .          .                 .              #[stable(feature = "rust1", since = "1.0.0")]
        .           .    .          .                 .              #[inline]
        .           .    .          .                 .              pub fn binary_search_by<'a, F>(&'a self, mut f: F) -> Result<usize, usize>
        .           .    .          .                 .              where
        .           .    .          .                 .                  F: FnMut(&'a T) -> Ordering,
        .           .    .          .                 .              {
        .           .    .          .                 .                  let mut size = self.len();
        0           0    0  2,000,000  (4.6%)         0                  if size == 0 {
        .           .    .          .                 .                      return Err(0);
        .           .    .          .                 .                  }
        .           .    .          .                 .                  let mut base = 0usize;
        .           .    .          .                 .          
        .           .    .          .                 .                  // This loop intentionally doesn't have an early exit if the comparison
        .           .    .          .                 .                  // returns Equal. We want the number of loop iterations to depend *only*
        .           .    .          .                 .                  // on the size of the input slice so that the CPU can reliably predict
        .           .    .          .                 .                  // the loop count.
        0           0    0 20,000,000 (46.4%) 1,000,013 (62.5%)          while size > 1 {
        0           0    0          0                 0                      let half = size / 2;
        0           0    0          0                 0                      let mid = base + half;
        .           .    .          .                 .          
        .           .    .          .                 .                      // SAFETY: the call is made safe by the following inconstants:
        .           .    .          .                 .                      // - `mid >= 0`: by definition
        .           .    .          .                 .                      // - `mid < size`: `mid = size / 2 + size / 4 + size / 8 ...`
        .           .    .          .                 .                      let cmp = f(unsafe { self.get_unchecked(mid) });
        .           .    .          .                 .          
        .           .    .          .                 .                      // Binary search interacts poorly with branch prediction, so force
        .           .    .          .                 .                      // the compiler to use conditional moves if supported by the target
-- line 2841 ----------------------------------------
-- line 2845 ----------------------------------------
        .           .    .          .                 .                      // This is imprecise in the case where `size` is odd and the
        .           .    .          .                 .                      // comparison returns Greater: the mid element still gets included
        .           .    .          .                 .                      // by `size` even though it's known to be larger than the element
        .           .    .          .                 .                      // being searched for.
        .           .    .          .                 .                      //
        .           .    .          .                 .                      // This is fine though: we gain more performance by keeping the
        .           .    .          .                 .                      // loop iteration count invariant (and thus predictable) than we
        .           .    .          .                 .                      // lose from considering one additional element.
        0           0    0          0                 0                      size -= half;
        .           .    .          .                 .                  }
        .           .    .          .                 .          
        .           .    .          .                 .                  // SAFETY: base is always in [0, size) because base <= mid.
        .           .    .          .                 .                  let cmp = f(unsafe { self.get_unchecked(base) });
        .           .    .          .                 .                  if cmp == Equal {
        .           .    .          .                 .                      // SAFETY: same as the `get_unchecked` above.
        .           .    .          .                 .                      unsafe { hint::assert_unchecked(base < self.len()) };
        .           .    .          .                 .                      Ok(base)
        .           .    .          .                 .                  } else {
        0           0    0          0                 0                      let result = base + (cmp == Less) as usize;
        .           .    .          .                 .                      // SAFETY: same as the `get_unchecked` above.
        .           .    .          .                 .                      // Note that this is `<=`, unlike the assume in the `Ok` path.
        .           .    .          .                 .                      unsafe { hint::assert_unchecked(result <= self.len()) };
        .           .    .          .                 .                      Err(result)
        .           .    .          .                 .                  }
        .           .    .          .                 .              }

--------------------------------------------------------------------------------
-- Annotated source file: /mnt/d/code/rust/hpc/src/profiling/statistical_profiling.rs
--------------------------------------------------------------------------------
Dr________________ D1mr_____________ DLmr Bc Bcm 

 1,000,003  (1.2%)         1  (0.0%)    0  0   0  <unknown (line 0)>

         .                 .            .  .   .  use std::usize;
         .                 .            .  .   .  
         .                 .            .  .   .  use rand::{distr::{Distribution, Uniform}, Rng, SeedableRng};
         .                 .            .  .   .  const N: usize = 1_000_000;
         .                 .            .  .   .  
         0                 0            0  0   0  pub fn statistical_profiling_init() -> Vec<usize> {
         .                 .            .  .   .      let mut rng = rand::rngs::StdRng::seed_from_u64(0);
         .                 .            .  .   .      let uniform = Uniform::new(0, usize::MAX).unwrap();
         .                 .            .  .   .      let mut vec: Vec<usize> = uniform.sample_iter(&mut rng).take(N).collect();
         .                 .            .  .   .      vec.sort_unstable();
         0                 0            0  0   0      vec
         7  (0.0%)         2  (0.0%)    0  0   0  }
         .                 .            .  .   .  
         0                 0            0  0   0  pub fn statistical_profiling_query() -> usize {
         .                 .            .  .   .      let mut rng = rand::rngs::StdRng::seed_from_u64(10);
         .                 .            .  .   .      let uniform = Uniform::new(0, usize::MAX).unwrap();
         1  (0.0%)         0            0  0   0      let vec = statistical_profiling_init();
         .                 .            .  .   .      let mut check_sum = 0;
         .                 .            .  .   .      for _ in 0..N {
         .                 .            .  .   .          let r = uniform.sample(&mut rng);
21,000,000 (25.4%) 9,479,753 (86.4%)    0  0   0          let p = vec.partition_point(|x| *x < r);
         0                 0            0  0   0          check_sum += p;
         .                 .            .  .   .      }
         .                 .            .  .   .      check_sum
         7  (0.0%)         1  (0.0%)    0  0   0  }
```

不幸的是，Cachegrind 只跟踪内存访问和分支预测。当瓶颈是由其他原因引起时，我们需要其他的模拟工具。
