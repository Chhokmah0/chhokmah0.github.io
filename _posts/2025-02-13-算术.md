---
title: 高性能计算-第六章-算术
date: 2025-2-13 12:00:00 +0800
categories: [笔记，高性能计算]
tags: [高性能计算]     # TAG names should always be lowercase
math: true
---
## 序 - 算术

正如我们在本书中提到的那样，了解指令集中的冷门指令可能会带来丰厚的回报，尤其是在 x86 这样的 CISC 平台上，目前它有大约 1000 到 4000 条不同的指令。

这些指令大多与算术相关，要想要高效地使用它们来优化算术操作，需要大量的知识、技能和创造力。因此，在本章中，我们将讨论数字表示及其在数值算法中的应用。

## 一 - 浮点数

使用浮点数来做算术的人，在对浮点数的了解程度上大概构成一个钟形曲线：

- 新手程序员会到处使用浮点数，就好像它是一个具有无限精度的神奇的数据类型一样。
- 然后，程序员发现 `0.1 + 0.2 != 0.3` 或者其它的一些奇怪现象。于是开始认为浮点数在每次计算中都会有随机的误差，而在很长时间内都拒绝了解浮点数的真正结构。
- 然后他们终于振作起来，阅读 IEEE-754 浮点数如何工作的规范，并开始适当地使用它们。

不幸的是，有太多程序员停留在阶段 2 了，对浮点运算产生了各种各样的误解——认为它从根本上说是不精确和不稳定的，而且比整数运算慢。

但这些都只是传言而已。由于有专门的指令，浮点运算通常比整数运算快。而且实数的表示是完全标准化的，在舍入方面遵循简单而确定的规则，允许我们可信地处理计算误差。

事实上，浮点数可靠到有一些高级编程语言根本没有整数类型，比方说 JavaScript，在里面只有 `number` 类型，底层是一个 64-bit 的 `double`。根据浮点数的计算规则，实际上所有在 `-2^53` 到 `2^53` 内的整数都可以被精确表示。所以从程序员的角度看，基本上没有什么使用整数类型的必要。

一个值得注意的例外是，当你需要对数字做逐位操作时，浮点数类型是不支持这样的操作的。在这种情况下，它们需要被转换为整数，这在支持 Javascript 的浏览器中使用得过于频繁，以至于 arm 添加了一个特殊的“FJCVTZS”指令，它代表“浮点 Javascript 转换为带符号的定点数（整数），并向零舍入”（Floating-point Javascript Convert to Signed fixed-point, rounding toward Zero）——这是一个有趣的软件-硬件反馈循环的例子。

不过，只要你不是专门用实数来行来模拟整数运算的 JavaScript 程序员，你大概率还是需要了解一下浮点数的运算规则。

### 实数的表示

如果我们需要处理实数（非整数），我们有一些可选的实现方法。在讨论浮点数前，我们可以先讨论一下可用的替代方案，以及其背后的动机——不然总会用不想用浮点数的人的。

#### 符号表示

第一种、同时也是最麻烦的方法是不存储结果值本身，而是存储它们的代数表达式。

有一个简单的例子。在一些应用中，比方说计算几何，除了加减乘除之外，还需要精确地进行除法，以生成一个有理数。我们可以用两个整数的比率精确表示它：

```cpp
struct r {
    int x, y;
};

r operator+(r a, r b) { return {a.x * b.y + a.y * b.x, a.y * b.y}; }
r operator*(r a, r b) { return {a.x * b.x, a.y * b.y}; }
r operator/(r a, r b) { return {a.x * b.x, a.y * b.y}; }
bool operator<(r a, r b) { return a.x * b.y < b.x * a.y; }
// ...and so on, you get the idea
```

这个分数应该是不可约的，这样就可以产生一个唯一的表示：

```cpp
struct r {
    int x, y;
    r(int x, int y) : x(x), y(y) {
        if (y < 0)
            x = -x, y = -y;
        int g = gcd(x, y);
        x /= g;
        y /= g;
    }
};
```

这就是计算机代数系统（如 WolframAlpha 或 SageMath）的工作原理：它们只对符号表达式进行操作，避免将任何东西计算为实数。

使用这种方法，我们可以获得绝对的精度，当我们只需要有理数的时候，它表现得非常好。但这需要很大的计算成本，因为在通常情况下，我们是需要以某种方式存储整个操作历史，并在每次执行新操作时都考虑它——随着操作历史的增长，这很快变得不可行。

#### 定点数

另一种方法是坚持使用整数，但将它们视为乘了一个固定的常数。这在本质上和为了更精确地测量而改变了测量单位是一样的。

由于有些值不能精确地表示，这使得计算不精确：我们需要将结果四舍五入到最接近的可表示值。

这种方法通常用于财务软件，在这些软件中，我们确实需要一种直接的方法来管理舍入误差，以便最终数字相加。例如，NASDAQ 在其股票清单中使用 $\frac{1}{10000}$ 美元作为基本单位，这意味着在所有交易中，逗号后的精确值为 4 位。

```cpp
struct money {
    uint v; // 1/10000th of a dollar
};

std::string to_string(money) {
    return std::format("${0}.{1:04d}", v / 10000, v % 10000);
}

money operator*(money x, money y) { return {x.v * y.v / 10000}; }
```

除了引入了舍入误差之外，另一个问题是当常数设置错误时，整个定点数很容易变得没有用处。如果正在处理的数字太大，则内部的整数值将溢出，如果数字太小，则会被舍入为零。有趣的是，当 NASDAQ 的股价接近 $\frac{2^{32} - 1}{10000} = 429,496.7295$ 时，前一种情况曾经成为纳斯达克的一个问题，无法用无符号 32 位整数容纳。

这个问题使得定点数从根本上不适合需要同时使用小数字和大数字的应用，例如，计算某些物理方程 $E=mc^2$。$m$ 通常小到原子的量级（$1.67 \cdot 10^{-27}$ kg），而 $c$ 却是光速（$3 \cdot 10^9$ m/s）。

#### 浮点数

在大多数数值应用中，我们主要关心的是相对误差。我们希望我们的计算结果与事实的差异不超过 0.01%，而并不关心 0.01% 具体是多少。

浮点数通过存储一定数量的最高有效数字和数字的数量级来解决这个问题。更准确地说，它们用一个整数（称为有效数或尾数）表示，并使用固定基数的指数（通常是 2 或 10）进行缩放。例如:

$$
1.2345=\underbrace{12345}_{有效数}\times {\underbrace{10}_{基数}}^{\overbrace{-4}^{指数}}
$$

计算机只在固定长度的二进制字节上操作，所以为硬件设计浮点数标准时，我们希望使用固定的二进制格式，其中一些位专用于有效数（用于更高的精度），一些专用于指数（用于更大的范围）。

例如给一种非常基础的实现：

```cpp
struct fp {
    int m; // mantissa
    int e; // exponent
};
```

这样我们既可以使用 $\pm m\times 2^e$ 的格式来表示，其中 $m$ 和 $e$ 都是有界并且可能为负的整数——分别对应负数和小数。这些数字的分布非常不均匀，在 $[0,1)$ 之间的数字数量和 $[1, +\infty)$ 之间的数字数量几乎一样。

注意到在这种表示下，数字的表示并不是唯一的，例如，有：

$$
1\tims 2^0 = 2 \times 2^{-1} = 256 \times 2^{-8} = \dots
$$

这对于某些应用（例如比较或者 hash）可能会有问题。为了解决这个问题，我们可以使用某种约定对这些表示进行规范化。在十进制中，标准形式总是在第一位非零的数字（6.022e23）后面加小数点，对于二进制，我们也可以这样做：

$$
42 = 10101_2 = 1.0101_2 \times 2^5
$$

注意到，根据这个规则，有效数的第一位总是1。显式地存储它是多余的，所以我们就假装它在那里，只存储其他的位。这样有效数对应于 $[0,1)$ 范围内的某个有理数，也是其被称为尾数的原因。可表示数的集合现在大致是：

$$
\{\pm (1+m)2^e | m = \frac{x}{2^{32}}, x \in [0, 2^{32}) \}
$$

$m$ 现在又变成非负值了，所以为了表示负数，我们还需要增加一个符号位：

```cpp
struct fp {
    bool s;     // sign: "0" for "+", "1" for "-" 
    unsigned m; // mantissa
    int e;      // exponent
};
```

现在，让我们尝试使用这个浮点数来实现一些算术运算——例如乘法。使用新的形式，结果应该是：

$$
\begin{aligned}
c =& a \cdot b \\
=& (s_a(1+m_a)2^{e_a})(s_b(1+m_b)2^{e_b}) \\
=& \underbrace{s_a s_b}_{s_c} \cdot (1+ \underbrace{m_a + m_b + m_a m_b}_{m_c}) \cdot 2^{\overbrace{e_a + e_b}^{e_c}}
\end{aligned}
$$

这样的分组计算看上去很容易，但有一些小细节：

- 新的尾数现在在 $[0,3)$ 的范围内。我们需要检查它是否大于 1，并通过以下公式将其规范化表示：

$$
1+m = (1+1) + (m -1) = (1 + \frac{m-1}{2})\cdot 2
$$

- 由于精度不足，结果数字可能（且很可能）无法精确表示。我们需要两倍的比特位数来处理 $m_a m_b$ 项，而我们能做的最好事情是将其舍入到最接近的可表示数字。

由于我们需要一些额外的位来正确处理尾数溢出问题，因此我们将从 $m$ 中保留一位，从而将其限制在 $[0, 2^{31})$ 范围内。

```cpp
fp operator*(fp a, fp b) {
    fp c;
    c.s = a.s ^ b.s;
    c.e = a.e + b.e;
    
    uint64_t x = a.m, y = b.m; // 转换到更宽的类型
    uint64_t m = (x << 31) + (y << 31) + x * y; // 62 或 63 位的结果
    if (m & (1<<62)) { // 检查是否溢出（大于 1）
        m -= (1<<62); // m -= 1;
        m >>= 1;
        c.e++;
    }
    m += (1<<30); // 加 0.5 从而和之后的 floor 操作共同达成四舍五入的效果。
    c.m = m >> 31;
    
    return c;
}
```

许多需要更高精度的应用程序以类似的方式实现 _软件浮点运算_。但当然，我们不希望每次将两个实数相乘时都执行这段代码编译出的约 10 条指令序列，因此在现代 CPU 中，浮点运算是在硬件中实现的——由于其复杂性，通常作为单独的协处理器。

x86 的浮点单元（通常称为 x87）具有单独的寄存器及其自己的小型指令集，支持内存操作、基本算术、三角函数以及一些常见操作，如对数、指数和平方根。为了使这些操作能够正确协同工作，我们需要澄清浮点数表示的一些额外细节——这些将在下一节中讨论。

## 二 - IEEE 754

在我们实现自己的浮点数时，其实省略了许多重要的细节：

- 我们应该用多少位来表示尾数和指数？
- 符号位是 `0` 的时候表示正数，还是反过来比较好？
- 浮点数总共占用多少 bits？
- 我们要怎么表示 0？
- 舍入规则具体是什么？
- 除 0 的时候会发生什么？
- 对负数开根会发生什么？
- 超出最大表示上界时会发生什么？
- 我们能否检测出上述三种情况发生了？

大多数早期的计算机都不支持浮点运算，当供应商开始添加浮点协处理器时，他们对这些问题的答案的看法各有不同。不同的实现使得可靠和可移植地使用浮点运算变得异常困难——特别是对于那些开发编译器的人。

到了 1985 年，电气和电子工程师协会发布了一个标准（称为 IEEE 754），该标准提供了浮点数应该如何工作的正式规范，该标准很快被供应商采用，几乎在所有通用计算机中使用。

### 浮点数的格式

和我们手动实现的浮点数一样，硬件浮点数也使用一 bit 作为符号位，以及一些指数位和尾数位。例如，标准的 32-bit `float` 最高位是符号位，后 8 位是指数位，剩下的 23 位是尾数位。

![IEEE 754 的浮点数标准](/assets/float.svg)
_IEEE 754 的浮点数标准（在 blog 左下角把背景颜色切换成白色可以看得更清楚）_

使用这种格式的一个原因是，你可以用无符号整数的比较器来比较两个浮点数的大小，除了可能在其中一个数字为负时翻转一些位。

出于同样的原因，指数位实际上是有偏置的：实际值比存储的无符号整数小 127。在上图的例子中：

$$
(-1)^0 \times 2^{01111100_2 - 127} \times (1 + 2^{-2}) = 2^{-3} \times 1.25 = 0.15625
$$

IEEE 754 和随后的一些标准定义了不止一种，而是几种大小不同的表示，值得关注的一些是：

| 类型      | 符号位 | 指数位 | 尾数位 | 总位数 | 近似的有效数字位数（10 进制下） |
| --------- | :----: | :----: | :----: | :----: | :-----------------------------: |
| single    |   1    |   8    |   23   |   32   |              ~7.2               |
| double    |   1    |   11   |   52   |   64   |              ~15.9              |
| half      |   1    |   5    |   10   |   16   |              ~3.3               |
| extended  |   1    |   15   |   64   |   80   |              ~19.2              |
| quadruple |   1    |   15   |  112   |  128   |              ~34.0              |
| bfloat16  |   1    |   8    |   7    |   16   |              ~2.3               |

不同的芯片对它们的支持并不相同：

- 大部分 CPU 都支持单双精度类型，在 C 语言中体现为 `float` 和 `double` 类型。
- Extended 类型是 x86 独有的，在 C 语言中体现为 `long double` 类型，同时 `long double` 在 Arm CPU 上会只是双精度类型。64 位的尾数可以准确地表达每一个 `long long` 整数。类似的还有一个 40 位的浮点数类型，拥有 32 位尾数。
- Quadruple 和 256 位的 octuple 格式仅用于特定的科学计算，一般不受硬件的支持。
- Half-precision 只支持一小部分操作，通常用于机器学习等应用程序，尤其是神经网络，因为它们倾向于执行大量的计算，却不需要很高的精度。
- Half-precision 正逐渐被 bfloat 所取代，它交换了 3 个尾数位，变得与单精度有相同的表示范围，从而实现与单精度的互操作性。它主要被专用硬件所采用：tpu、fgpa 和 gpu。bfloat 名字的意思是“Brain float”。

低精度类型占用更少的内存带宽来移动它们，并且通常也消耗更少的周期来操作，这就是为什么在误差允许的情况下，它们会更受欢迎一些。

深度学习，作为一个非常出名的计算密集型领域，创造了对低精度矩阵乘法的巨大需求。这导致制造商甚至会开发单独的硬件，或者至少添加专门的指令来支持这些类型的计算——值得注意的是，谷歌开发了一种名为 TPU（张量处理单元）的定制芯片，专门用于给 128x128 的 bfloat 矩阵做乘法，而 NVIDIA 在其所有较新的 gpu 上都添加了“张量核”，能够一次执行 4x4 矩阵乘法。

除了它们的大小之外，所有浮点类型的大多数行为都是相同的，现在我们将讨论这一点。

### 处理边际情况

整数算术处理极端情况时（如除零）的默认方式是崩溃。

但有时，软件崩溃会导致真正的物理崩溃。1996 年，Ariane 5（欧空局用来将物体送入近地轨道的太空运载火箭）的首次飞行以灾难性的爆炸告终，原因是算术错误导致中断的策略。在这种情况下，浮点数到整数转换溢出导致导航系统认为它偏离了轨道并进行了大幅修正，最终导致了 2 亿美元火箭的解体。

有一种方法可以优雅地处理像这样的极端情况：硬件中断。当出现异常时，CPU 会做下面的事情：

- 中断目前运行的程序；
- 将所有相关信息打包到一个称为“中断向量”的数据结构中；
- 将它传递给操作系统，如果可能的话，操作系统反过来调用处理代码（“try-except”块），否则将终止程序。

这是一个非常复杂的机制，值得专门写一篇文章。但由于这是一本关于性能的书，我们只需要知道它相当慢，在诸如导航火箭之类的实时系统中并不理想。

### NaN，0，无穷

浮点运算通常用来处理嘈杂的真实数据。在这里的异常比整数情况下的异常要常见得多，因此，处理它们的默认行为是不同的。浮点数运算结果会被替换为一个特殊的值，而不会中断程序的执行（除非程序员明确地希望它这样做）。

这种值的第一种类型是两个无穷大：一个正无穷大和一个负无穷大。如果计算的结果不能在可表示的范围内，则会生成它们，并且在算术中也会这样处理它们。

$$
\begin{aligned}
-\infty < x < \infty \\
\infty + x = \infty \\
x / \infty = 0
\end{aligned}
$$

如果除零的时候会发生什么？事实上，在浮点数中是明确的，因为浮点数实际上有两个 0：一个正零，一个负零：

$$
\begin{aligned}
\frac{1}{+0}=+\infty \\
\frac{1}{-0}=-\infty
\end{aligned}
$$

一个有趣的事实是，`x+0.0` 不能被简化为 `x`，而 `x+(-0.0)` 却可以。因此从这方面来说，使用负零作为浮点数的初始化值可以帮助编译器更好地进行优化。`+0.0` 不能优化的主要原因是 IEEE 规定 `+0.0 + -0.0 == +0.0`，并不是加法的单位元，优化掉会使得 `x == -0.0` 时的结果是不正确的。两个零的存在经常引起这样的头痛问题——好消息是，如果想禁用此行为，可以向编译器传递 `fno-signed-zeros`。

零的编码方式是将除了符号位外的所有位设置为 0。无穷大的编码方式是将其所有指数位设置为 1，将所有尾数位设置为 0，并用符号位区分正无穷大和负无穷大。

另一种类型是“Not a Number”（NaN），它是由于数学上错误的操作而产生的：

$$
\log(-1), \arccos(1.01),\infty-\infty,-\infty+\infty,0\times \infty, 0 \div 0, \infty \div \infty
$$

NaN 有两种类型：信号型 NaN（signaling NaN）和静默型 NaN（quiet NaN）。信号型 NaN 会引发异常标志，根据 FPU 的配置，可能会导致硬件中断，而静默型 NaN 则会在几乎任何算术操作中传播，产生更多的 NaN。

在二进制中，两种 NaN 的指数位都设置为全 1，而尾数部分则不全为零（和无穷大区分开来）。请注意，NaN 有许多有效的编码方式。

### 扩展阅读

如果还想深入了解，可以阅读经典的“[每个计算机科学家都应该知道的浮点算术](https://www.itu.dk/~sestoft/bachelor/IEEE754_article.pdf)”和[介绍 Grisu3 的论文](https://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf)，这是当前用于打印浮点数的最新技术。
